[2025-05-22T13:28:08.169+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-05-22T13:28:08.178+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: kafka_to_minio_to_spark.spark_etl scheduled__2025-05-21T16:00:00+00:00 [queued]>
[2025-05-22T13:28:08.183+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: kafka_to_minio_to_spark.spark_etl scheduled__2025-05-21T16:00:00+00:00 [queued]>
[2025-05-22T13:28:08.183+0000] {taskinstance.py:2865} INFO - Starting attempt 57 of 58
[2025-05-22T13:28:08.188+0000] {taskinstance.py:2888} INFO - Executing <Task(SparkSubmitOperator): spark_etl> on 2025-05-21 16:00:00+00:00
[2025-05-22T13:28:08.190+0000] {standard_task_runner.py:72} INFO - Started process 78 to run task
[2025-05-22T13:28:08.192+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'kafka_to_minio_to_spark', 'spark_etl', 'scheduled__2025-05-21T16:00:00+00:00', '--job-id', '337', '--raw', '--subdir', 'DAGS_FOLDER/testlog_ml.py', '--cfg-path', '/tmp/tmpmvw00jlu']
[2025-05-22T13:28:08.193+0000] {standard_task_runner.py:105} INFO - Job 337: Subtask spark_etl
[2025-05-22T13:28:08.212+0000] {task_command.py:467} INFO - Running <TaskInstance: kafka_to_minio_to_spark.spark_etl scheduled__2025-05-21T16:00:00+00:00 [running]> on host e8ae60c88781
[2025-05-22T13:28:08.241+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='kafka_to_minio_to_spark' AIRFLOW_CTX_TASK_ID='spark_etl' AIRFLOW_CTX_EXECUTION_DATE='2025-05-21T16:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='57' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-21T16:00:00+00:00'
[2025-05-22T13:28:08.242+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-05-22T13:28:08.256+0000] {base.py:84} INFO - Retrieving connection 'spark'
[2025-05-22T13:28:08.257+0000] {spark_submit.py:341} INFO - Spark-Submit cmd: spark-submit --master local --conf spark.hadoop.fs.s3a.endpoint=http://3.38.135.214:9000 --conf spark.hadoop.fs.s3a.access.key=minioadmin --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.hadoop.fs.s3a.aws.credentials.provider= --jars /opt/spark/jars/hadoop-aws-3.3.1.jar,/opt/spark/jars/aws-java-sdk-bundle-1.11.901.jar,/opt/spark/jars/postgresql-42.7.4.jar --name arrow-spark /opt/spark/testlog_ml_spark.py
[2025-05-22T13:28:09.020+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-05-22T13:28:09.604+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SparkContext: Running Spark version 3.5.1
[2025-05-22T13:28:09.605+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-05-22T13:28:09.606+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SparkContext: Java version 17.0.15
[2025-05-22T13:28:09.614+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO ResourceUtils: ==============================================================
[2025-05-22T13:28:09.614+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-05-22T13:28:09.615+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO ResourceUtils: ==============================================================
[2025-05-22T13:28:09.615+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SparkContext: Submitted application: arrow-spark
[2025-05-22T13:28:09.621+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-05-22T13:28:09.624+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO ResourceProfile: Limiting resource is cpu
[2025-05-22T13:28:09.625+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-05-22T13:28:09.642+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SecurityManager: Changing view acls to: ***
[2025-05-22T13:28:09.642+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SecurityManager: Changing modify acls to: ***
[2025-05-22T13:28:09.647+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SecurityManager: Changing view acls groups to:
[2025-05-22T13:28:09.647+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SecurityManager: Changing modify acls groups to:
[2025-05-22T13:28:09.647+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ***; groups with view permissions: EMPTY; users with modify permissions: ***; groups with modify permissions: EMPTY
[2025-05-22T13:28:09.726+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO Utils: Successfully started service 'sparkDriver' on port 39397.
[2025-05-22T13:28:09.736+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SparkEnv: Registering MapOutputTracker
[2025-05-22T13:28:09.748+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SparkEnv: Registering BlockManagerMaster
[2025-05-22T13:28:09.759+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-05-22T13:28:09.759+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-05-22T13:28:09.761+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-05-22T13:28:09.768+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f769485a-06c8-44da-85b9-2e84971efc23
[2025-05-22T13:28:09.773+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-05-22T13:28:09.779+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-05-22T13:28:09.821+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-05-22T13:28:09.846+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-05-22T13:28:09.858+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SparkContext: Added JAR file:///opt/spark/jars/hadoop-aws-3.3.1.jar at spark://e8ae60c88781:39397/jars/hadoop-aws-3.3.1.jar with timestamp 1747920489601
[2025-05-22T13:28:09.859+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SparkContext: Added JAR file:///opt/spark/jars/aws-java-sdk-bundle-1.11.901.jar at spark://e8ae60c88781:39397/jars/aws-java-sdk-bundle-1.11.901.jar with timestamp 1747920489601
[2025-05-22T13:28:09.859+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO SparkContext: Added JAR file:///opt/spark/jars/postgresql-42.7.4.jar at spark://e8ae60c88781:39397/jars/postgresql-42.7.4.jar with timestamp 1747920489601
[2025-05-22T13:28:09.899+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO Executor: Starting executor ID driver on host e8ae60c88781
[2025-05-22T13:28:09.900+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO Executor: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-05-22T13:28:09.900+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO Executor: Java version 17.0.15
[2025-05-22T13:28:09.903+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-05-22T13:28:09.904+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3111325b for default.
[2025-05-22T13:28:09.911+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO Executor: Fetching spark://e8ae60c88781:39397/jars/aws-java-sdk-bundle-1.11.901.jar with timestamp 1747920489601
[2025-05-22T13:28:09.932+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO TransportClientFactory: Successfully created connection to e8ae60c88781/172.27.0.5:39397 after 10 ms (0 ms spent in bootstraps)
[2025-05-22T13:28:09.934+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:09 INFO Utils: Fetching spark://e8ae60c88781:39397/jars/aws-java-sdk-bundle-1.11.901.jar to /tmp/spark-01eac6bd-9150-4bd6-a9ed-ad9f95de7cda/userFiles-8194d2c6-5a01-496f-a20a-3159f9e0f6d9/fetchFileTemp3401820036171751129.tmp
[2025-05-22T13:28:10.197+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO Executor: Adding file:/tmp/spark-01eac6bd-9150-4bd6-a9ed-ad9f95de7cda/userFiles-8194d2c6-5a01-496f-a20a-3159f9e0f6d9/aws-java-sdk-bundle-1.11.901.jar to class loader default
[2025-05-22T13:28:10.198+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO Executor: Fetching spark://e8ae60c88781:39397/jars/postgresql-42.7.4.jar with timestamp 1747920489601
[2025-05-22T13:28:10.199+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO Utils: Fetching spark://e8ae60c88781:39397/jars/postgresql-42.7.4.jar to /tmp/spark-01eac6bd-9150-4bd6-a9ed-ad9f95de7cda/userFiles-8194d2c6-5a01-496f-a20a-3159f9e0f6d9/fetchFileTemp7008070990890735074.tmp
[2025-05-22T13:28:10.211+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO Executor: Adding file:/tmp/spark-01eac6bd-9150-4bd6-a9ed-ad9f95de7cda/userFiles-8194d2c6-5a01-496f-a20a-3159f9e0f6d9/postgresql-42.7.4.jar to class loader default
[2025-05-22T13:28:10.212+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO Executor: Fetching spark://e8ae60c88781:39397/jars/hadoop-aws-3.3.1.jar with timestamp 1747920489601
[2025-05-22T13:28:10.212+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO Utils: Fetching spark://e8ae60c88781:39397/jars/hadoop-aws-3.3.1.jar to /tmp/spark-01eac6bd-9150-4bd6-a9ed-ad9f95de7cda/userFiles-8194d2c6-5a01-496f-a20a-3159f9e0f6d9/fetchFileTemp8996405153255877668.tmp
[2025-05-22T13:28:10.219+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO Executor: Adding file:/tmp/spark-01eac6bd-9150-4bd6-a9ed-ad9f95de7cda/userFiles-8194d2c6-5a01-496f-a20a-3159f9e0f6d9/hadoop-aws-3.3.1.jar to class loader default
[2025-05-22T13:28:10.224+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37895.
[2025-05-22T13:28:10.225+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO NettyBlockTransferService: Server created on e8ae60c88781:37895
[2025-05-22T13:28:10.226+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-05-22T13:28:10.229+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T13:28:10.231+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO BlockManagerMasterEndpoint: Registering block manager e8ae60c88781:37895 with 434.4 MiB RAM, BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T13:28:10.233+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T13:28:10.233+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T13:28:10.362+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-05-22T13:28:10.362+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO SharedState: Warehouse path is 'file:/opt/***/spark-warehouse'.
[2025-05-22T13:28:10.658+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2025-05-22T13:28:10.662+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[2025-05-22T13:28:10.665+0000] {spark_submit.py:492} INFO - 25/05/22 13:28:10 INFO MetricsSystemImpl: s3a-file-system metrics system started
[2025-05-22T14:02:24.433+0000] {job.py:229} INFO - Heartbeat recovered after 2030.99 seconds
[2025-05-22T14:32:41.392+0000] {job.py:229} INFO - Heartbeat recovered after 1761.51 seconds
[2025-05-22T14:53:00.724+0000] {job.py:229} INFO - Heartbeat recovered after 1194.09 seconds
[2025-05-22T14:53:01.326+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:01 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1195460 ms exceeds timeout 120000 ms
[2025-05-22T14:53:01.331+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:01 WARN SparkContext: Killing executors is not supported by current scheduler.
[2025-05-22T14:53:04.909+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:04 INFO Executor: Told to re-register on heartbeat
[2025-05-22T14:53:04.910+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:04 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T14:53:04.910+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T14:53:04.913+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:04 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T14:53:04.914+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T14:53:04.914+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T14:53:04.914+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T14:53:04.914+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T14:53:04.915+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T14:53:04.915+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T14:53:04.915+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T14:53:04.915+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T14:53:04.916+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T14:53:04.916+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T14:53:04.916+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T14:53:04.917+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T14:53:04.918+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T14:53:04.918+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T14:53:04.918+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T14:53:04.918+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T14:53:04.918+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T14:53:04.918+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T14:53:04.919+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T14:53:04.919+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T14:53:04.919+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T14:53:04.919+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T14:53:04.919+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T14:53:04.919+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T14:53:04.919+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T14:53:04.920+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T14:53:04.920+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T14:53:04.920+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T14:53:04.920+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T14:53:04.920+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T14:53:04.920+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T14:53:04.921+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T14:53:04.921+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T14:53:04.921+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T14:53:04.921+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T14:53:04.922+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T14:53:04.922+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T14:53:04.922+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T14:53:04.922+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T14:53:04.923+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T14:53:04.923+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T14:53:04.923+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T14:53:04.923+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T14:53:04.923+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:04.923+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:04.924+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:04.924+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:04.924+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:04.924+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:04.925+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:04.925+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:04.925+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:04.925+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:04.925+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T14:53:04.925+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:04.926+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:04.926+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:04.926+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:04.926+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:04.926+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:04.926+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:04.927+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:04.927+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:04.927+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:04.927+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T14:53:04.928+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:04.928+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T14:53:04.928+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T14:53:04.928+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T14:53:04.928+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T14:53:04.929+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T14:53:04.929+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T14:53:04.929+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T14:53:04.929+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T14:53:04.929+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T14:53:04.929+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:04.929+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:04.930+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:04.930+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:04.930+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T14:53:04.930+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T14:53:04.930+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T14:53:04.930+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T14:53:04.930+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T14:53:04.931+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T14:53:04.931+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:04.931+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:04.931+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:04.931+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:04.931+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:04.931+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:04.932+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:04.932+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:04.932+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:04.932+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:04.932+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T14:53:04.932+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T14:53:04.933+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T14:53:04.933+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T14:53:04.933+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T14:53:04.933+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T14:53:04.933+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T14:53:04.933+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:04 ERROR Inbox: Ignoring error
[2025-05-22T14:53:04.933+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T14:53:04.934+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T14:53:04.934+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T14:53:04.934+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T14:53:04.934+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T14:53:04.934+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T14:53:04.934+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T14:53:04.934+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T14:53:04.935+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T14:53:04.935+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T14:53:04.935+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T14:53:04.935+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T14:53:04.935+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T14:53:04.935+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T14:53:04.935+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T14:53:04.936+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T14:53:04.936+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T14:53:04.936+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T14:53:04.936+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T14:53:04.936+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T14:53:04.936+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T14:53:04.937+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T14:53:04.937+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T14:53:04.937+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T14:53:04.937+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T14:53:04.937+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T14:53:04.937+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:04.938+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:04.938+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:04.938+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:04.939+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:04.939+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:04.939+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:04.939+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:04.939+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:04.940+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:04.940+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T14:53:04.940+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:04.940+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:04.941+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:04.941+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:04.941+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:04.941+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:04.942+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:04.942+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:04.942+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:04.942+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:04.942+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T14:53:04.942+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:04.943+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T14:53:04.943+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T14:53:04.943+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T14:53:04.943+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T14:53:04.943+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T14:53:04.944+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T14:53:04.944+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T14:53:04.944+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T14:53:04.944+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T14:53:04.944+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:04.944+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:04.945+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:04.945+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:04.945+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T14:53:04.946+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T14:53:04.946+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T14:53:04.947+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T14:53:04.947+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T14:53:04.947+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T14:53:04.948+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:04.948+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:04.948+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:04.948+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:04.948+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:04.948+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:04.949+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:04.949+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:04.949+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:04.949+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:04.949+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T14:53:04.949+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T14:53:04.950+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T14:53:04.950+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T14:53:04.950+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T14:53:04.950+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T14:53:04.950+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T14:53:14.922+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:14 INFO Executor: Told to re-register on heartbeat
[2025-05-22T14:53:14.926+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:14 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T14:53:14.930+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T14:53:14.934+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:14 ERROR Inbox: Ignoring error
[2025-05-22T14:53:14.935+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T14:53:14.936+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T14:53:14.936+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T14:53:14.937+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T14:53:14.938+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T14:53:14.938+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T14:53:14.939+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T14:53:14.939+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T14:53:14.940+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T14:53:14.940+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T14:53:14.941+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T14:53:14.942+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T14:53:14.942+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T14:53:14.942+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T14:53:14.943+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T14:53:14.943+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T14:53:14.943+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T14:53:14.944+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T14:53:14.944+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T14:53:14.944+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T14:53:14.944+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T14:53:14.945+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T14:53:14.945+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T14:53:14.945+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T14:53:14.946+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T14:53:14.946+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T14:53:14.946+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:14.946+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:14.947+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:14.947+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:14.947+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:14.947+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:14.948+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:14.948+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:14.948+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:14.948+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:14.948+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T14:53:14.949+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:14.949+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:14.949+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:14.950+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:14.950+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:14.950+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:14.950+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:14.950+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:14.951+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:14.951+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:14.951+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T14:53:14.951+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:14.951+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T14:53:14.952+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T14:53:14.952+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T14:53:14.952+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T14:53:14.952+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T14:53:14.953+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T14:53:14.953+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T14:53:14.953+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T14:53:14.953+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T14:53:14.953+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:14.954+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:14.954+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:14.954+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:14.954+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T14:53:14.954+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T14:53:14.955+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T14:53:14.955+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T14:53:14.955+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T14:53:14.955+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T14:53:14.955+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:14.955+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:14.956+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:14.956+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:14.956+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:14.956+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:14.956+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:14.956+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:14.957+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:14.957+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:14.957+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T14:53:14.957+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T14:53:14.957+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T14:53:14.958+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T14:53:14.958+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T14:53:14.958+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T14:53:14.958+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T14:53:14.958+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:14 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T14:53:14.959+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T14:53:14.959+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T14:53:14.959+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T14:53:14.959+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T14:53:14.959+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T14:53:14.960+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T14:53:14.960+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T14:53:14.960+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T14:53:14.960+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T14:53:14.960+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T14:53:14.961+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T14:53:14.961+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T14:53:14.961+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T14:53:14.961+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T14:53:14.961+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T14:53:14.961+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T14:53:14.962+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T14:53:14.962+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T14:53:14.962+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T14:53:14.962+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T14:53:14.962+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T14:53:14.962+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T14:53:14.963+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T14:53:14.963+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T14:53:14.963+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T14:53:14.963+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T14:53:14.963+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T14:53:14.963+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T14:53:14.964+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T14:53:14.964+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T14:53:14.964+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T14:53:14.964+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T14:53:14.964+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T14:53:14.964+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T14:53:14.965+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T14:53:14.965+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T14:53:14.965+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T14:53:14.965+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T14:53:14.965+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T14:53:14.965+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T14:53:14.966+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T14:53:14.966+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T14:53:14.966+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T14:53:14.966+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:14.966+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:14.966+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:14.967+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:14.967+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:14.967+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:14.967+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:14.967+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:14.967+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:14.968+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:14.968+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T14:53:14.968+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:14.968+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:14.968+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:14.968+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:14.969+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:14.969+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:14.969+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:14.969+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:14.969+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:14.969+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:14.970+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T14:53:14.970+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:14.970+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T14:53:14.970+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T14:53:14.970+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T14:53:14.970+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T14:53:14.970+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T14:53:14.971+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T14:53:14.971+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T14:53:14.971+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T14:53:14.971+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T14:53:14.971+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:14.971+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:14.971+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:14.972+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:14.972+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T14:53:14.972+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T14:53:14.972+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T14:53:14.972+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T14:53:14.972+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T14:53:14.972+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T14:53:14.973+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:14.973+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:14.973+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:14.973+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:14.973+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:14.973+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:14.974+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:14.974+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:14.974+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:14.974+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:14.974+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T14:53:14.974+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T14:53:14.975+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T14:53:14.975+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T14:53:14.975+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T14:53:14.975+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T14:53:14.975+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T14:53:24.916+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:24 INFO Executor: Told to re-register on heartbeat
[2025-05-22T14:53:24.918+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:24 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T14:53:24.920+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T14:53:24.922+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:24 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T14:53:24.924+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T14:53:24.925+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T14:53:24.926+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T14:53:24.926+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T14:53:24.927+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T14:53:24.928+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T14:53:24.930+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T14:53:24.930+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T14:53:24.931+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T14:53:24.931+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T14:53:24.932+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T14:53:24.932+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T14:53:24.932+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T14:53:24.933+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T14:53:24.933+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T14:53:24.933+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T14:53:24.934+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T14:53:24.934+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T14:53:24.935+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T14:53:24.935+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T14:53:24.935+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T14:53:24.936+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T14:53:24.936+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T14:53:24.936+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T14:53:24.937+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T14:53:24.937+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T14:53:24.937+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T14:53:24.938+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T14:53:24.938+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T14:53:24.938+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T14:53:24.938+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T14:53:24.939+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T14:53:24.939+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T14:53:24.940+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T14:53:24.940+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T14:53:24.940+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T14:53:24.941+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T14:53:24.941+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T14:53:24.941+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T14:53:24.942+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T14:53:24.942+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T14:53:24.942+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T14:53:24.943+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T14:53:24.943+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:24.943+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:24.943+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:24.944+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:24.944+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:24.944+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:24.945+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:24.945+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:24.945+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:24.945+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:24.946+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T14:53:24.946+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:24.946+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:24.946+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:24.947+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:24.947+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:24.947+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:24.947+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:24.948+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:24.948+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:24.948+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:24.948+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T14:53:24.949+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:24.949+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T14:53:24.949+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T14:53:24.949+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T14:53:24.950+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T14:53:24.950+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T14:53:24.950+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T14:53:24.950+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T14:53:24.950+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T14:53:24.951+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T14:53:24.951+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:24.951+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:24.951+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:24.952+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:24.952+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T14:53:24.952+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T14:53:24.952+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T14:53:24.952+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T14:53:24.953+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T14:53:24.953+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T14:53:24.953+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:24.953+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:24.953+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:24.953+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:24.954+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:24.954+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:24.954+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:24.954+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:24.954+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:24.955+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:24.955+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T14:53:24.955+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T14:53:24.955+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T14:53:24.955+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T14:53:24.956+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T14:53:24.956+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T14:53:24.956+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T14:53:24.956+0000] {spark_submit.py:492} INFO - 25/05/22 14:53:24 ERROR Inbox: Ignoring error
[2025-05-22T14:53:24.956+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T14:53:24.957+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T14:53:24.957+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T14:53:24.957+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T14:53:24.957+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T14:53:24.957+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T14:53:24.958+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T14:53:24.958+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T14:53:24.958+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T14:53:24.958+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T14:53:24.958+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T14:53:24.959+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T14:53:24.959+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T14:53:24.959+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T14:53:24.959+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T14:53:24.959+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T14:53:24.959+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T14:53:24.960+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T14:53:24.960+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T14:53:24.960+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T14:53:24.960+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T14:53:24.960+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T14:53:24.960+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T14:53:24.961+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T14:53:24.961+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T14:53:24.961+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T14:53:24.961+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:24.961+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:24.961+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:24.962+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:24.962+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:24.962+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:24.962+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:24.962+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:24.963+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:24.963+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:24.963+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T14:53:24.963+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:24.963+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:24.963+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:24.964+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:24.964+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:24.964+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:24.964+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:24.964+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:24.964+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:24.965+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:24.965+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T14:53:24.965+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:24.965+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T14:53:24.965+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T14:53:24.965+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T14:53:24.965+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T14:53:24.966+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T14:53:24.966+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T14:53:24.966+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T14:53:24.966+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T14:53:24.966+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T14:53:24.966+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:24.967+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:24.967+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:24.967+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:24.967+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T14:53:24.967+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T14:53:24.967+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T14:53:24.968+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T14:53:24.968+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T14:53:24.968+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T14:53:24.968+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T14:53:24.968+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T14:53:24.968+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T14:53:24.968+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T14:53:24.969+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T14:53:24.969+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T14:53:24.969+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T14:53:24.969+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T14:53:24.969+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T14:53:24.969+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T14:53:24.969+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T14:53:24.970+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T14:53:24.970+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T14:53:24.970+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T14:53:24.970+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T14:53:24.970+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T14:53:24.970+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:25:10.542+0000] {job.py:229} INFO - Heartbeat recovered after 1904.57 seconds
[2025-05-22T15:25:14.447+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:14 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:25:14.450+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:14 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:25:14.451+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:25:14.453+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:14 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:25:14.454+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:25:14.455+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:25:14.455+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:25:14.456+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:25:14.457+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:25:14.457+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:25:14.458+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:25:14.458+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:25:14.459+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:25:14.459+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:25:14.460+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:25:14.460+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:25:14.461+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:25:14.461+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:25:14.462+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:25:14.463+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:25:14.463+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:25:14.464+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:25:14.465+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:25:14.465+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:25:14.466+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:25:14.466+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:25:14.467+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:25:14.467+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:25:14.468+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:25:14.468+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:25:14.468+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:25:14.469+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:25:14.469+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:25:14.470+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:25:14.470+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:25:14.471+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:25:14.471+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:25:14.471+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:25:14.471+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:25:14.472+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:25:14.472+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:25:14.472+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:25:14.473+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:25:14.473+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:25:14.473+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:25:14.473+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:25:14.474+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:25:14.474+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:14.474+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:14.474+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:14.474+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:14.475+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:14.475+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:14.475+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:14.475+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:14.476+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:14.476+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:14.476+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:14.476+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:14.477+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:14.477+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:14.477+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:14.477+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:14.477+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:14.478+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:14.478+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:14.478+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:14.478+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:14.479+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:14.479+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:14.479+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:25:14.479+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:25:14.479+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:25:14.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:25:14.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:25:14.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:25:14.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:25:14.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:25:14.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:25:14.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:14.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:14.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:14.482+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:14.482+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:25:14.482+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:25:14.482+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:25:14.482+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:25:14.483+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:25:14.483+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:25:14.483+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:14.483+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:14.484+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:14.484+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:14.484+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:14.484+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:14.484+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:14.484+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:14.485+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:14.485+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:14.485+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:25:14.485+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:25:14.486+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:25:14.486+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:25:14.486+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:25:14.486+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:25:14.486+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:25:14.487+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:14 ERROR Inbox: Ignoring error
[2025-05-22T15:25:14.487+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:25:14.487+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:25:14.487+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:25:14.487+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:25:14.488+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:25:14.488+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:25:14.488+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:25:14.488+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:25:14.488+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:25:14.489+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:25:14.489+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:25:14.489+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:25:14.489+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:25:14.489+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:25:14.489+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:25:14.490+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:25:14.490+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:25:14.490+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:25:14.490+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:25:14.490+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:25:14.490+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:25:14.491+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:25:14.491+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:25:14.491+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:25:14.491+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:25:14.491+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:25:14.491+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:14.492+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:14.492+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:14.492+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:14.492+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:14.492+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:14.492+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:14.493+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:14.493+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:14.493+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:14.493+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:14.493+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:14.493+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:14.494+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:14.494+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:14.494+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:14.494+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:14.494+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:14.494+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:14.495+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:14.495+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:14.495+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:14.495+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:14.495+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:25:14.495+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:25:14.496+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:25:14.496+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:25:14.496+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:25:14.496+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:25:14.496+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:25:14.496+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:25:14.497+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:25:14.497+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:14.497+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:14.497+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:14.497+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:14.497+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:25:14.497+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:25:14.498+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:25:14.498+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:25:14.498+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:25:14.498+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:25:14.498+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:14.498+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:14.499+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:14.499+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:14.499+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:14.499+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:14.499+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:14.499+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:14.499+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:14.500+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:14.500+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:25:14.500+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:25:14.500+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:25:14.500+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:25:14.500+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:25:14.500+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:25:14.501+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:25:24.447+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:24 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:25:24.448+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:24 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:25:24.450+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:25:24.450+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:24 ERROR Inbox: Ignoring error
[2025-05-22T15:25:24.450+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:25:24.451+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:25:24.452+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:25:24.452+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:25:24.453+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:25:24.453+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:25:24.453+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:25:24.454+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:25:24.454+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:25:24.454+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:25:24.454+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:25:24.455+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:25:24.455+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:25:24.455+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:25:24.456+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:25:24.456+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:25:24.456+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:25:24.457+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:25:24.457+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:25:24.458+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:25:24.458+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:25:24.458+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:25:24.459+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:25:24.459+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:25:24.460+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:25:24.460+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:25:24.461+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:24.461+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:24.462+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:24.462+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:24.463+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:24.463+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:24.463+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:24.464+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:24.464+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:24.464+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:24.465+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:24.465+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:24.465+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:24.465+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:24.466+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:24.466+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:24.466+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:24.467+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:24.467+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:24.467+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:24.467+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:24.468+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:24.468+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:24.468+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:25:24.468+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:25:24.469+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:25:24.469+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:25:24.469+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:25:24.470+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:25:24.470+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:25:24.470+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:25:24.470+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:25:24.471+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:24.471+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:24.471+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:24.471+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:24.471+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:25:24.471+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:25:24.472+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:25:24.472+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:25:24.472+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:25:24.472+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:25:24.472+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:24.472+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:24.472+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:24.472+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:24.473+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:24.473+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:24.473+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:24.473+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:24.473+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:24.473+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:24.473+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:25:24.473+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:25:24.474+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:25:24.474+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:25:24.474+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:25:24.474+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:25:24.474+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:25:24.474+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:24 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:25:24.474+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:25:24.474+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:25:24.475+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:25:24.475+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:25:24.475+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:25:24.475+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:25:24.475+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:25:24.475+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:25:24.475+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:25:24.476+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:25:24.476+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:25:24.476+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:25:24.476+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:25:24.476+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:25:24.476+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:25:24.476+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:25:24.476+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:25:24.477+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:25:24.477+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:25:24.477+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:25:24.477+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:25:24.477+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:25:24.477+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:25:24.477+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:25:24.477+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:25:24.478+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:25:24.478+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:25:24.478+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:25:24.478+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:25:24.478+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:25:24.478+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:25:24.478+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:25:24.478+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:25:24.479+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:25:24.479+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:25:24.479+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:25:24.479+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:25:24.479+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:25:24.479+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:25:24.479+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:25:24.479+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:25:24.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:25:24.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:25:24.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:24.480+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:24.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:24.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:24.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:24.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:24.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:24.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:24.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:24.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:24.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:24.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:24.481+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:24.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:24.482+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:24.482+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:24.482+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:24.482+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:24.482+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:24.482+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:24.482+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:24.483+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:24.483+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:24.483+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:25:24.483+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:25:24.483+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:25:24.483+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:25:24.483+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:25:24.483+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:25:24.483+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:25:24.483+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:25:24.484+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:25:24.484+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:24.484+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:24.484+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:24.484+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:24.484+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:25:24.484+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:25:24.485+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:25:24.485+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:25:24.485+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:25:24.485+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:25:24.485+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:24.485+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:24.485+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:24.485+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:24.485+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:24.485+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:24.485+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:24.486+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:24.486+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:24.486+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:24.486+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:25:24.486+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:25:24.486+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:25:24.486+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:25:24.486+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:25:24.486+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:25:24.486+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:25:34.452+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:34 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:25:34.453+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:34 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:25:34.453+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:25:34.454+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:34 ERROR Inbox: Ignoring error
[2025-05-22T15:25:34.454+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:25:34.455+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:25:34.455+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:25:34.455+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:25:34.456+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:25:34.456+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:25:34.457+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:25:34.457+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:25:34.457+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:25:34.458+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:25:34.458+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:25:34.458+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:25:34.459+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:25:34.460+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:25:34.460+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:25:34.460+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:25:34.461+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:25:34.461+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:25:34.461+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:25:34.461+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:25:34.462+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:25:34.462+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:25:34.462+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:25:34.462+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:25:34.463+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:25:34.463+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:25:34.463+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:34.463+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:34.464+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:34.464+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:34.464+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:34.464+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:34.465+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:34.465+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:34.465+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:34.466+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:34.466+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:34.466+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:34.467+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:34.467+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:34.467+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:34.468+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:34.468+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:34.469+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:34.469+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:34.469+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:34.469+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:34.469+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:34.470+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:34.470+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:25:34.470+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:25:34.470+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:25:34.470+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:25:34.471+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:25:34.471+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:25:34.471+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:25:34.472+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:25:34.478+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:25:34.478+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:34.478+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:34.478+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:34.479+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:34.479+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:25:34.479+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:25:34.479+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:25:34.479+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:25:34.479+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:25:34.480+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:25:34.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:34.480+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:34.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:34.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:34.480+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:34.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:34.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:34.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:34.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:34.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:34.481+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:25:34.482+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:25:34.482+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:25:34.482+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:25:34.482+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:25:34.482+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:25:34.482+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:25:34.482+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:34 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:25:34.483+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:25:34.483+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:25:34.483+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:25:34.483+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:25:34.483+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:25:34.484+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:25:34.484+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:25:34.484+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:25:34.485+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:25:34.485+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:25:34.490+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:25:34.491+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:25:34.491+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:25:34.491+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:25:34.491+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:25:34.491+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:25:34.491+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:25:34.492+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:25:34.492+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:25:34.492+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:25:34.492+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:25:34.492+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:25:34.492+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:25:34.492+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:25:34.493+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:25:34.493+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:25:34.493+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:25:34.493+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:25:34.493+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:25:34.493+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:25:34.494+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:25:34.494+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:25:34.494+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:25:34.494+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:25:34.494+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:25:34.494+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:25:34.494+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:25:34.495+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:25:34.495+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:25:34.495+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:25:34.495+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:25:34.495+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:25:34.495+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:25:34.496+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:34.496+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:34.496+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:34.496+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:34.496+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:34.496+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:34.496+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:34.497+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:34.497+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:34.497+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:34.497+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:34.497+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:34.497+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:34.497+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:34.498+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:34.498+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:34.498+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:34.498+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:34.498+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:34.498+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:34.498+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:34.499+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:34.499+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:34.499+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:25:34.499+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:25:34.499+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:25:34.499+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:25:34.499+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:25:34.500+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:25:34.500+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:25:34.500+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:25:34.500+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:25:34.500+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:34.500+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:34.500+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:34.501+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:34.501+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:25:34.501+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:25:34.501+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:25:34.501+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:25:34.501+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:25:34.501+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:25:34.502+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:34.502+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:34.502+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:34.502+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:34.502+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:34.502+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:34.502+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:34.502+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:34.503+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:34.503+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:34.503+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:25:34.503+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:25:34.503+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:25:34.503+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:25:34.503+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:25:34.504+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:25:34.504+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:25:44.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:44 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:25:44.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:44 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:25:44.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:25:44.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:44 ERROR Inbox: Ignoring error
[2025-05-22T15:25:44.806+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:25:44.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:25:44.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:25:44.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:25:44.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:25:44.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:25:44.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:25:44.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:25:44.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:25:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:25:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:25:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:25:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:25:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:25:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:25:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:25:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:25:44.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:25:44.814+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:25:44.814+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:25:44.815+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:25:44.815+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:25:44.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:25:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:25:44.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:25:44.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:25:44.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:44.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:44.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:44.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:44.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:44.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:44.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:44.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:44.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:44.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:44.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:44.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:44.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:44.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:25:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:25:44.823+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:25:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:25:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:25:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:25:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:25:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:25:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:25:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:25:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:25:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:25:44.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:25:44.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:25:44.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:25:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:44.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:25:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:25:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:25:44.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:25:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:25:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:25:44.827+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:25:44.827+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:44 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:25:44.827+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:25:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:25:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:25:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:25:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:25:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:25:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:25:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:25:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:25:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:25:44.828+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:25:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:25:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:25:44.829+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:25:44.829+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:25:44.829+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:25:44.829+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:25:44.829+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:25:44.829+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:25:44.829+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:25:44.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:25:44.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:25:44.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:25:44.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:25:44.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:25:44.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:25:44.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:25:44.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:25:44.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:25:44.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:25:44.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:25:44.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:25:44.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:25:44.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:25:44.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:25:44.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:25:44.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:25:44.831+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:25:44.831+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:25:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:25:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:25:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:25:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:25:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:44.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:25:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:25:44.835+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:25:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:25:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:25:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:25:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:25:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:25:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:25:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:25:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:25:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:25:44.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:25:44.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:25:44.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:25:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:44.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:25:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:25:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:25:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:25:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:25:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:25:44.838+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:25:54.801+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:54 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:25:54.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:54 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:25:54.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:25:54.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:54 ERROR Inbox: Ignoring error
[2025-05-22T15:25:54.806+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:25:54.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:25:54.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:25:54.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:25:54.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:25:54.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:25:54.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:25:54.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:25:54.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:25:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:25:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:25:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:25:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:25:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:25:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:25:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:25:54.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:25:54.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:25:54.815+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:25:54.815+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:25:54.815+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:25:54.816+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:25:54.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:25:54.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:25:54.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:25:54.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:25:54.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:54.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:54.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:54.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:54.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:54.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:54.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:54.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:25:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:25:54.826+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:25:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:25:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:25:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:25:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:25:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:25:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:25:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:25:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:25:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:25:54.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:25:54.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:25:54.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:25:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:54.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:25:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:25:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:25:54.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:25:54.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:25:54.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:25:54.833+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:25:54.833+0000] {spark_submit.py:492} INFO - 25/05/22 15:25:54 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:25:54.833+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:25:54.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:25:54.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:25:54.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:25:54.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:25:54.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:25:54.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:25:54.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:25:54.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:25:54.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:25:54.835+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:25:54.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:25:54.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:25:54.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:25:54.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:25:54.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:25:54.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:25:54.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:25:54.837+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:25:54.837+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:25:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:25:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:25:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:25:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:25:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:25:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:25:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:25:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:25:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:25:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:25:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:25:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:25:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:25:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:25:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:25:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:25:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:25:54.840+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:25:54.840+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:25:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:25:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:25:54.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:25:54.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:25:54.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:54.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:54.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:54.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:54.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:54.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:54.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:54.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:54.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:54.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:54.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:54.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:54.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:25:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:25:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:25:54.845+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:25:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:25:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:25:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:25:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:25:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:25:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:25:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:25:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:25:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:25:54.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:25:54.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:25:54.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:25:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:25:54.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:25:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:25:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:25:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:25:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:25:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:25:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:25:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:25:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:25:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:25:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:25:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:25:54.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:25:54.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:25:54.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:25:54.850+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:26:04.799+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:04 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:26:04.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:04 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:26:04.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:26:04.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:04 ERROR Inbox: Ignoring error
[2025-05-22T15:26:04.807+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:04.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:04.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:26:04.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:26:04.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:26:04.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:26:04.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:26:04.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:26:04.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:26:04.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:26:04.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:26:04.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:26:04.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:26:04.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:26:04.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:26:04.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:26:04.813+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:26:04.814+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:26:04.814+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:26:04.814+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:26:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:26:04.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:26:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:26:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:26:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:04.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:04.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:26:04.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:26:04.831+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:04.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:26:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:26:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:26:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:26:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:26:04.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:26:04.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:04.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:04.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:04.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:04.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:26:04.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:26:04.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:26:04.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:26:04.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:26:04.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:26:04.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:04.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:04.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:04.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:04.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:04.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:04.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:04.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:04.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:04.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:04.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:26:04.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:26:04.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:26:04.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:26:04.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:26:04.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:26:04.839+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:26:04.839+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:04 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:26:04.840+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:04.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:04.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:04.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:04.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:26:04.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:26:04.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:26:04.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:26:04.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:26:04.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:26:04.842+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:04.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:26:04.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:26:04.842+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:26:04.842+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:26:04.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:26:04.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:26:04.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:26:04.843+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:26:04.843+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:04.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:04.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:04.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:04.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:26:04.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:26:04.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:26:04.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:26:04.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:26:04.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:26:04.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:26:04.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:26:04.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:26:04.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:26:04.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:26:04.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:26:04.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:26:04.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:26:04.847+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:26:04.847+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:26:04.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:26:04.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:26:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:26:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:26:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:04.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:04.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:04.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:04.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:04.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:04.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:04.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:04.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:04.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:04.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:04.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:04.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:04.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:04.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:04.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:04.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:04.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:04.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:04.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:04.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:04.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:04.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:26:04.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:26:04.852+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:04.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:26:04.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:26:04.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:26:04.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:26:04.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:26:04.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:26:04.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:04.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:04.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:04.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:04.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:26:04.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:26:04.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:26:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:26:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:26:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:26:04.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:04.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:04.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:26:04.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:26:04.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:26:04.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:26:04.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:26:04.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:26:04.857+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:26:14.801+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:14 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:26:14.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:14 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:26:14.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:26:14.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:14 ERROR Inbox: Ignoring error
[2025-05-22T15:26:14.806+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:14.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:14.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:14.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:14.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:26:14.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:26:14.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:26:14.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:26:14.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:26:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:26:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:26:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:26:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:26:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:26:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:26:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:26:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:26:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:26:14.814+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:26:14.815+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:26:14.815+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:26:14.815+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:26:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:26:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:26:14.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:26:14.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:26:14.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:14.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:14.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:26:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:26:14.826+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:26:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:26:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:26:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:26:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:26:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:26:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:26:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:26:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:26:14.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:26:14.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:26:14.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:26:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:14.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:26:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:26:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:26:14.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:26:14.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:26:14.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:26:14.834+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:26:14.834+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:14 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:26:14.834+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:26:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:26:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:26:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:26:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:26:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:26:14.836+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:26:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:26:14.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:26:14.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:26:14.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:26:14.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:26:14.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:26:14.838+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:26:14.838+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:26:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:26:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:26:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:26:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:26:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:26:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:26:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:26:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:26:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:26:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:26:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:26:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:26:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:26:14.841+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:26:14.841+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:26:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:26:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:26:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:26:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:26:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:14.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:14.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:26:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:26:14.847+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:26:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:26:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:26:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:26:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:26:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:26:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:26:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:26:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:26:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:26:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:26:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:26:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:14.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:26:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:26:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:26:14.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:26:14.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:26:14.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:26:14.852+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:26:24.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:24 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:26:24.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:24 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:26:24.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:26:24.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:24 ERROR Inbox: Ignoring error
[2025-05-22T15:26:24.808+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:24.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:24.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:24.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:26:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:26:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:26:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:26:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:26:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:26:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:26:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:26:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:26:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:26:24.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:26:24.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:26:24.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:26:24.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:26:24.815+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:26:24.815+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:26:24.816+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:26:24.816+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:26:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:26:24.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:26:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:26:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:26:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:24.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:24.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:24.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:24.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:24.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:24.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:24.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:24.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:24.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:24.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:24.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:24.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:24.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:24.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:26:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:26:24.824+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:26:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:26:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:26:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:26:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:26:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:26:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:26:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:26:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:26:24.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:26:24.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:26:24.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:26:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:24.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:26:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:26:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:26:24.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:26:24.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:26:24.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:26:24.833+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:26:24.833+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:24 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:26:24.834+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:26:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:26:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:26:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:26:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:26:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:26:24.836+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:26:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:26:24.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:26:24.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:26:24.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:26:24.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:26:24.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:26:24.837+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:26:24.837+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:24.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:24.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:24.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:24.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:26:24.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:26:24.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:26:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:26:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:26:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:26:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:26:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:26:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:26:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:26:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:26:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:26:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:26:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:26:24.841+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:26:24.841+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:26:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:26:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:26:24.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:26:24.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:26:24.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:24.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:24.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:24.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:26:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:26:24.846+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:26:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:26:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:26:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:26:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:26:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:26:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:26:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:26:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:26:24.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:26:24.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:26:24.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:26:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:24.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:26:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:26:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:26:24.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:26:24.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:26:24.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:26:24.852+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:26:34.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:34 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:26:34.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:34 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:26:34.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:26:34.809+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:34 ERROR Inbox: Ignoring error
[2025-05-22T15:26:34.810+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:26:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:26:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:26:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:26:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:26:34.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:26:34.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:26:34.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:26:34.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:26:34.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:26:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:26:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:26:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:26:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:26:34.815+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:26:34.815+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:26:34.815+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:26:34.815+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:26:34.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:26:34.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:26:34.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:26:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:26:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:34.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:34.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:26:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:26:34.823+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:26:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:26:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:26:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:26:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:26:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:26:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:26:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:26:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:26:34.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:26:34.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:26:34.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:26:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:34.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:26:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:26:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:26:34.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:26:34.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:26:34.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:26:34.832+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:26:34.832+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:34 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:26:34.833+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:34.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:34.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:34.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:34.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:26:34.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:26:34.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:26:34.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:26:34.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:26:34.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:26:34.835+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:34.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:26:34.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:26:34.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:26:34.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:26:34.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:26:34.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:26:34.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:26:34.837+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:26:34.837+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:26:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:26:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:26:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:26:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:26:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:26:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:26:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:26:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:26:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:26:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:26:34.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:26:34.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:26:34.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:26:34.840+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:26:34.840+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:26:34.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:26:34.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:26:34.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:26:34.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:26:34.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:34.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:34.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:34.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:34.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:34.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:34.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:34.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:34.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:34.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:34.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:34.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:34.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:26:34.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:26:34.846+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:34.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:26:34.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:26:34.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:26:34.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:26:34.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:26:34.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:26:34.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:34.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:34.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:26:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:26:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:26:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:26:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:26:34.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:26:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:34.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:26:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:26:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:26:34.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:26:34.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:26:34.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:26:34.852+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:26:44.799+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:44 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:26:44.800+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:44 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:26:44.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:26:44.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:44 ERROR Inbox: Ignoring error
[2025-05-22T15:26:44.804+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:44.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:44.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:44.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:44.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:26:44.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:26:44.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:26:44.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:26:44.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:26:44.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:26:44.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:26:44.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:26:44.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:26:44.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:26:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:26:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:26:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:26:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:26:44.812+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:26:44.812+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:26:44.813+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:26:44.813+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:26:44.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:26:44.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:26:44.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:26:44.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:26:44.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:44.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:44.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:44.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:44.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:44.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:44.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:44.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:44.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:44.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:44.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:44.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:44.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:44.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:26:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:26:44.823+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:26:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:26:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:26:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:26:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:26:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:26:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:26:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:26:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:26:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:26:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:26:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:26:44.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:26:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:26:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:26:44.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:26:44.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:26:44.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:26:44.831+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:26:44.831+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:44 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:26:44.831+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:44.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:26:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:26:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:26:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:26:44.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:26:44.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:26:44.833+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:44.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:26:44.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:26:44.834+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:26:44.834+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:26:44.834+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:26:44.834+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:26:44.834+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:26:44.835+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:26:44.835+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:44.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:26:44.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:26:44.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:26:44.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:26:44.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:26:44.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:26:44.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:26:44.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:26:44.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:26:44.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:26:44.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:26:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:26:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:26:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:26:44.838+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:26:44.838+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:26:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:26:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:26:44.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:26:44.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:26:44.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:44.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:44.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:44.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:44.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:44.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:44.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:44.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:44.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:44.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:44.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:44.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:44.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:44.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:44.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:44.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:26:44.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:26:44.843+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:44.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:26:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:26:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:26:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:26:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:26:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:26:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:26:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:26:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:26:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:26:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:26:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:26:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:26:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:26:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:26:44.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:26:44.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:26:44.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:26:44.848+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:26:54.801+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:54 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:26:54.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:54 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:26:54.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:26:54.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:54 ERROR Inbox: Ignoring error
[2025-05-22T15:26:54.806+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:54.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:54.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:54.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:54.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:26:54.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:26:54.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:26:54.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:26:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:26:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:26:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:26:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:26:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:26:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:26:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:26:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:26:54.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:26:54.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:26:54.814+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:26:54.815+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:26:54.815+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:26:54.816+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:26:54.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:26:54.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:26:54.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:26:54.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:26:54.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:54.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:54.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:54.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:54.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:54.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:54.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:54.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:54.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:54.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:26:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:26:54.825+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:26:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:26:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:26:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:26:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:26:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:26:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:26:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:26:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:26:54.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:26:54.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:26:54.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:26:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:54.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:26:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:26:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:26:54.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:26:54.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:26:54.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:26:54.832+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:26:54.833+0000] {spark_submit.py:492} INFO - 25/05/22 15:26:54 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:26:54.833+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:54.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:54.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:54.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:54.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:26:54.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:26:54.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:26:54.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:26:54.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:26:54.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:26:54.835+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:54.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:26:54.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:26:54.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:26:54.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:26:54.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:26:54.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:26:54.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:26:54.837+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:26:54.837+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:26:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:26:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:26:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:26:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:26:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:26:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:26:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:26:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:26:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:26:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:26:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:26:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:26:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:26:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:26:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:26:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:26:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:26:54.842+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:26:54.842+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:26:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:26:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:26:54.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:26:54.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:26:54.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:54.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:54.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:26:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:26:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:26:54.848+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:26:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:26:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:26:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:26:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:26:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:26:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:26:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:26:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:26:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:26:54.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:26:54.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:26:54.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:26:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:26:54.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:26:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:26:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:26:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:26:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:26:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:26:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:26:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:26:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:26:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:26:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:26:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:26:54.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:26:54.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:26:54.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:26:54.853+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:27:04.798+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:04 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:27:04.799+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:04 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:27:04.799+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:27:04.799+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:04 ERROR Inbox: Ignoring error
[2025-05-22T15:27:04.800+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:04.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:04.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:04.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:27:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:27:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:27:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:27:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:27:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:27:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:27:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:27:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:27:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:27:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:27:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:27:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:27:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:27:04.803+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:27:04.803+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:27:04.804+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:27:04.804+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:27:04.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:27:04.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:27:04.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:27:04.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:27:04.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:04.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:04.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:04.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:04.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:04.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:04.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:04.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:04.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:04.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:04.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:04.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:04.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:04.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:04.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:04.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:04.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:27:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:27:04.809+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:27:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:27:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:27:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:27:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:27:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:27:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:27:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:27:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:27:04.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:27:04.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:27:04.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:27:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:04.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:27:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:27:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:27:04.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:27:04.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:27:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:27:04.814+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:27:04.814+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:04 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:27:04.814+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:27:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:27:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:27:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:27:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:27:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:27:04.815+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:27:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:27:04.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:27:04.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:27:04.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:27:04.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:27:04.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:27:04.817+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:27:04.817+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:27:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:27:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:27:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:27:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:27:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:27:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:27:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:27:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:27:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:27:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:27:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:27:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:27:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:27:04.819+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:27:04.819+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:27:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:27:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:27:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:27:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:27:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:04.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:27:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:27:04.824+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:27:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:27:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:27:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:27:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:27:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:27:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:27:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:27:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:27:04.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:27:04.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:27:04.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:27:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:04.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:27:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:27:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:27:04.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:27:04.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:27:04.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:27:04.830+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:27:14.799+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:14 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:27:14.801+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:14 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:27:14.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:27:14.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:14 ERROR Inbox: Ignoring error
[2025-05-22T15:27:14.804+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:14.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:14.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:14.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:14.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:27:14.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:27:14.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:27:14.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:27:14.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:27:14.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:27:14.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:27:14.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:27:14.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:27:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:27:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:27:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:27:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:27:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:27:14.813+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:27:14.813+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:27:14.814+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:27:14.814+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:27:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:27:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:27:14.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:27:14.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:27:14.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:14.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:14.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:14.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:14.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:27:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:27:14.825+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:27:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:27:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:27:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:27:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:27:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:27:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:27:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:27:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:27:14.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:27:14.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:27:14.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:27:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:14.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:27:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:27:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:27:14.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:27:14.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:27:14.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:27:14.832+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:27:14.832+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:14 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:27:14.833+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:14.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:14.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:14.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:14.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:27:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:27:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:27:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:27:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:27:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:27:14.835+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:27:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:27:14.835+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:27:14.835+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:27:14.835+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:27:14.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:27:14.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:27:14.836+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:27:14.836+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:27:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:27:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:27:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:27:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:27:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:27:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:27:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:27:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:27:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:27:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:27:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:27:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:27:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:27:14.840+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:27:14.840+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:27:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:27:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:27:14.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:27:14.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:27:14.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:14.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:14.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:14.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:27:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:27:14.845+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:27:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:27:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:27:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:27:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:27:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:27:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:27:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:27:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:27:14.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:27:14.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:27:14.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:27:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:14.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:27:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:27:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:27:14.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:27:14.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:27:14.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:27:14.850+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:27:24.797+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:24 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:27:24.798+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:24 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:27:24.798+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:27:24.798+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:24 ERROR Inbox: Ignoring error
[2025-05-22T15:27:24.799+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:24.799+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:24.799+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:24.799+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:24.799+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:27:24.799+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:27:24.799+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:27:24.799+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:27:24.799+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:27:24.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:27:24.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:27:24.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:27:24.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:27:24.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:27:24.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:27:24.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:27:24.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:27:24.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:27:24.800+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:27:24.801+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:27:24.801+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:27:24.801+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:27:24.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:27:24.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:27:24.801+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:27:24.801+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:27:24.801+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:24.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:24.802+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:24.802+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:24.802+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:24.802+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:24.802+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:24.802+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:24.802+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:24.802+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:24.802+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:24.802+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:24.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:24.803+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:24.803+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:24.803+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:24.803+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:24.803+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:24.803+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:24.803+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:24.803+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:24.803+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:24.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:24.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:27:24.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:27:24.804+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:24.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:27:24.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:27:24.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:27:24.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:27:24.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:27:24.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:27:24.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:24.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:24.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:24.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:24.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:27:24.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:27:24.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:27:24.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:27:24.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:27:24.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:27:24.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:24.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:24.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:24.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:24.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:24.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:24.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:24.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:24.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:24.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:24.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:27:24.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:27:24.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:27:24.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:27:24.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:27:24.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:27:24.807+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:27:24.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:24 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:27:24.808+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:24.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:24.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:24.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:24.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:27:24.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:27:24.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:27:24.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:27:24.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:27:24.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:27:24.809+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:24.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:27:24.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:27:24.809+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:27:24.809+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:27:24.809+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:27:24.809+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:27:24.809+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:27:24.810+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:27:24.810+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:27:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:27:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:27:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:27:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:27:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:27:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:27:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:27:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:27:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:27:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:27:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:27:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:27:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:27:24.811+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:27:24.812+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:27:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:27:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:27:24.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:27:24.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:27:24.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:24.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:24.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:24.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:24.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:24.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:24.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:24.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:24.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:24.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:24.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:24.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:24.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:24.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:24.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:24.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:24.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:24.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:24.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:24.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:24.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:27:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:27:24.815+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:27:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:27:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:27:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:27:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:27:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:27:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:24.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:24.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:24.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:24.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:27:24.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:27:24.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:27:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:27:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:27:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:27:24.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:24.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:24.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:27:24.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:27:24.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:27:24.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:27:24.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:27:24.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:27:24.818+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:27:34.799+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:34 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:27:34.801+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:34 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:27:34.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:27:34.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:34 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:27:34.805+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:34.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:34.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:34.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:34.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:27:34.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:27:34.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:27:34.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:27:34.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:27:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:27:34.810+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:27:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:27:34.811+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:27:34.812+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:27:34.812+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:27:34.812+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:27:34.813+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:27:34.813+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:27:34.814+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:34.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:34.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:27:34.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:27:34.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:27:34.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:27:34.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:27:34.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:27:34.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:27:34.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:27:34.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:27:34.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:27:34.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:27:34.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:27:34.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:27:34.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:27:34.820+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:27:34.820+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:27:34.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:27:34.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:27:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:27:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:27:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:34.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:34.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:27:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:27:34.834+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:34.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:27:34.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:27:34.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:27:34.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:27:34.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:27:34.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:27:34.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:34.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:34.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:34.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:34.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:27:34.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:27:34.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:27:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:27:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:27:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:27:34.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:34.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:34.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:34.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:34.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:34.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:34.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:34.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:34.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:34.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:27:34.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:27:34.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:27:34.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:27:34.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:27:34.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:27:34.842+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:27:34.842+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:34 ERROR Inbox: Ignoring error
[2025-05-22T15:27:34.842+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:34.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:34.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:34.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:34.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:27:34.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:27:34.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:27:34.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:27:34.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:27:34.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:27:34.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:27:34.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:27:34.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:27:34.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:27:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:27:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:27:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:27:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:27:34.846+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:27:34.847+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:27:34.847+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:27:34.847+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:27:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:27:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:27:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:27:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:27:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:34.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:34.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:27:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:27:34.853+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:27:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:27:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:27:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:27:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:27:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:27:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:27:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:27:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:27:34.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:27:34.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:27:34.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:27:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:34.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:27:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:27:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:27:34.859+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:27:34.859+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:27:34.859+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:27:34.859+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:27:44.801+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:44 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:27:44.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:44 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:27:44.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:27:44.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:44 ERROR Inbox: Ignoring error
[2025-05-22T15:27:44.806+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:44.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:44.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:44.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:44.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:27:44.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:27:44.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:27:44.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:27:44.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:27:44.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:27:44.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:27:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:27:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:27:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:27:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:27:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:27:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:27:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:27:44.813+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:27:44.814+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:27:44.814+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:27:44.814+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:27:44.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:27:44.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:27:44.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:27:44.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:27:44.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:44.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:44.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:44.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:44.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:44.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:44.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:44.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:44.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:44.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:44.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:44.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:44.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:44.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:44.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:27:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:27:44.823+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:27:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:27:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:27:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:27:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:27:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:27:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:44.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:27:44.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:27:44.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:27:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:27:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:27:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:27:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:27:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:27:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:27:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:27:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:27:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:27:44.833+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:27:44.833+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:44 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:27:44.833+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:44.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:44.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:44.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:44.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:27:44.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:27:44.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:27:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:27:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:27:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:27:44.835+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:44.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:27:44.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:27:44.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:27:44.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:27:44.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:27:44.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:27:44.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:27:44.837+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:27:44.838+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:27:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:27:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:27:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:27:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:27:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:27:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:27:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:27:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:27:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:27:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:27:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:27:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:27:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:27:44.841+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:27:44.842+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:27:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:27:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:27:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:27:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:27:44.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:44.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:44.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:44.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:27:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:27:44.847+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:27:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:27:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:27:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:27:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:27:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:27:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:27:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:27:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:27:44.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:27:44.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:27:44.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:27:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:44.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:27:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:27:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:27:44.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:27:44.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:27:44.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:27:44.852+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:27:54.800+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:54 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:27:54.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:54 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:27:54.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:27:54.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:54 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:27:54.808+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:54.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:54.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:54.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:27:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:27:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:27:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:27:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:27:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:27:54.813+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:54.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:27:54.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:27:54.814+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:27:54.815+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:27:54.815+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:27:54.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:27:54.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:27:54.817+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:27:54.817+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:54.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:54.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:54.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:54.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:27:54.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:27:54.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:27:54.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:27:54.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:27:54.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:27:54.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:27:54.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:27:54.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:27:54.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:27:54.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:27:54.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:27:54.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:27:54.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:27:54.824+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:27:54.824+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:27:54.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:27:54.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:27:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:27:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:27:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:54.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:54.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:27:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:27:54.831+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:27:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:27:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:27:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:27:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:27:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:27:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:27:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:27:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:27:54.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:27:54.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:27:54.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:27:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:54.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:54.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:54.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:54.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:54.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:54.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:54.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:54.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:27:54.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:27:54.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:27:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:27:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:27:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:27:54.838+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:27:54.838+0000] {spark_submit.py:492} INFO - 25/05/22 15:27:54 ERROR Inbox: Ignoring error
[2025-05-22T15:27:54.838+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:27:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:27:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:27:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:27:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:27:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:27:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:27:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:27:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:27:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:27:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:27:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:27:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:27:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:27:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:27:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:27:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:27:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:27:54.842+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:27:54.842+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:27:54.842+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:27:54.842+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:27:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:27:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:27:54.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:27:54.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:27:54.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:54.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:54.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:27:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:27:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:27:54.847+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:27:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:27:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:27:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:27:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:27:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:27:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:27:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:27:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:27:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:27:54.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:27:54.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:27:54.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:27:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:27:54.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:27:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:27:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:27:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:27:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:27:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:27:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:27:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:27:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:27:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:27:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:27:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:27:54.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:27:54.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:27:54.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:27:54.852+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:28:04.800+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:04 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:28:04.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:04 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:28:04.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:28:04.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:04 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:28:04.806+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:04.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:04.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:04.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:28:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:28:04.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:28:04.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:28:04.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:28:04.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:28:04.810+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:04.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:28:04.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:28:04.811+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:28:04.811+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:28:04.812+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:28:04.812+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:28:04.813+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:28:04.813+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:28:04.813+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:28:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:28:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:28:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:28:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:28:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:28:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:28:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:28:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:28:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:28:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:28:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:28:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:28:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:28:04.818+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:28:04.819+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:28:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:28:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:28:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:28:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:28:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:04.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:04.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:28:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:28:04.827+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:28:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:28:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:28:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:28:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:28:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:28:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:28:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:28:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:28:04.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:28:04.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:28:04.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:28:04.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:04.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:04.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:04.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:04.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:04.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:28:04.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:28:04.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:28:04.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:28:04.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:28:04.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:28:04.834+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:28:04.835+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:04 ERROR Inbox: Ignoring error
[2025-05-22T15:28:04.835+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:04.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:04.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:04.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:04.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:28:04.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:28:04.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:28:04.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:28:04.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:28:04.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:28:04.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:28:04.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:28:04.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:28:04.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:28:04.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:28:04.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:28:04.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:28:04.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:28:04.844+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:28:04.844+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:28:04.844+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:28:04.845+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:28:04.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:28:04.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:28:04.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:28:04.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:28:04.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:04.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:04.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:04.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:04.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:04.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:04.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:04.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:04.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:04.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:04.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:04.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:04.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:04.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:04.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:04.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:04.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:04.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:04.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:28:04.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:28:04.852+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:04.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:28:04.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:28:04.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:28:04.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:28:04.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:28:04.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:28:04.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:04.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:04.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:04.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:04.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:28:04.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:28:04.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:28:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:28:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:28:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:28:04.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:04.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:04.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:04.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:28:04.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:28:04.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:28:04.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:28:04.858+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:28:04.858+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:28:04.858+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:28:14.799+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:14 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:28:14.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:14 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:28:14.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:28:14.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:14 ERROR Inbox: Ignoring error
[2025-05-22T15:28:14.804+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:14.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:14.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:14.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:14.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:28:14.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:28:14.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:28:14.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:28:14.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:28:14.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:28:14.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:28:14.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:28:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:28:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:28:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:28:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:28:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:28:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:28:14.813+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:28:14.814+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:28:14.814+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:28:14.814+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:28:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:28:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:28:14.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:28:14.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:28:14.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:14.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:14.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:14.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:28:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:28:14.825+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:28:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:28:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:28:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:28:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:28:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:28:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:28:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:28:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:28:14.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:28:14.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:28:14.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:28:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:14.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:28:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:28:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:28:14.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:28:14.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:28:14.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:28:14.832+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:28:14.832+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:14 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:28:14.832+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:14.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:14.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:14.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:14.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:28:14.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:28:14.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:28:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:28:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:28:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:28:14.834+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:28:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:28:14.835+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:28:14.835+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:28:14.835+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:28:14.835+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:28:14.835+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:28:14.836+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:28:14.836+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:28:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:28:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:28:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:28:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:28:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:28:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:28:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:28:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:28:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:28:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:28:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:28:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:28:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:28:14.839+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:28:14.839+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:28:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:28:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:28:14.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:28:14.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:28:14.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:14.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:14.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:14.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:14.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:14.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:14.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:14.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:14.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:28:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:28:14.844+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:28:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:28:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:28:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:28:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:28:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:28:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:28:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:28:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:28:14.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:28:14.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:28:14.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:28:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:14.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:28:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:28:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:28:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:28:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:28:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:28:14.849+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:28:24.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:24 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:28:24.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:24 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:28:24.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:28:24.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:24 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:28:24.809+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:28:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:28:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:28:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:28:24.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:28:24.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:28:24.815+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:24.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:28:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:28:24.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:28:24.817+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:28:24.817+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:28:24.818+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:28:24.818+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:28:24.819+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:28:24.819+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:24.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:24.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:24.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:24.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:28:24.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:28:24.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:28:24.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:28:24.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:28:24.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:28:24.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:28:24.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:28:24.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:28:24.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:28:24.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:28:24.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:28:24.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:28:24.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:28:24.826+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:28:24.827+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:28:24.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:28:24.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:28:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:28:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:28:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:24.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:28:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:28:24.833+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:28:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:28:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:28:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:28:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:28:24.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:28:24.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:24.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:24.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:24.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:24.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:28:24.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:28:24.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:28:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:28:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:28:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:28:24.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:24.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:24.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:24.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:24.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:24.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:24.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:24.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:24.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:24.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:28:24.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:28:24.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:28:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:28:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:28:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:28:24.840+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:28:24.840+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:24 ERROR Inbox: Ignoring error
[2025-05-22T15:28:24.840+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:28:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:28:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:28:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:28:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:28:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:28:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:28:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:28:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:28:24.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:28:24.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:28:24.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:28:24.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:28:24.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:28:24.844+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:28:24.844+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:28:24.844+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:28:24.844+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:28:24.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:28:24.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:28:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:28:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:28:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:24.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:24.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:28:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:28:24.850+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:28:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:28:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:28:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:28:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:28:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:28:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:28:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:28:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:28:24.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:28:24.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:28:24.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:28:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:24.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:24.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:24.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:24.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:24.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:24.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:24.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:24.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:24.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:28:24.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:28:24.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:28:24.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:28:24.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:28:24.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:28:24.855+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:28:34.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:34 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:28:34.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:34 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:28:34.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:28:34.809+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:34 ERROR Inbox: Ignoring error
[2025-05-22T15:28:34.809+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:28:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:28:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:28:34.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:28:34.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:28:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:28:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:28:34.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:28:34.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:28:34.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:28:34.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:28:34.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:28:34.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:28:34.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:28:34.817+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:28:34.818+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:28:34.818+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:28:34.818+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:28:34.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:28:34.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:28:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:28:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:28:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:34.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:34.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:28:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:28:34.829+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:28:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:28:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:28:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:28:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:28:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:28:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:28:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:28:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:28:34.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:28:34.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:28:34.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:28:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:34.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:34.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:34.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:34.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:34.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:28:34.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:28:34.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:28:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:28:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:28:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:28:34.838+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:28:34.838+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:34 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:28:34.838+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:28:34.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:28:34.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:28:34.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:28:34.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:28:34.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:28:34.842+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:34.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:28:34.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:28:34.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:28:34.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:28:34.844+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:28:34.844+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:28:34.844+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:28:34.844+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:28:34.844+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:34.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:34.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:34.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:28:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:28:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:28:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:28:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:28:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:28:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:28:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:28:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:28:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:28:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:28:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:28:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:28:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:28:34.849+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:28:34.849+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:28:34.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:28:34.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:28:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:28:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:28:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:34.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:34.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:28:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:28:34.855+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:28:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:28:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:28:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:28:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:28:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:28:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:28:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:28:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:28:34.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:28:34.858+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:28:34.858+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:28:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:34.858+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:34.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:28:34.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:28:34.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:28:34.860+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:28:34.860+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:28:34.860+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:28:34.860+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:28:44.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:44 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:28:44.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:44 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:28:44.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:28:44.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:44 ERROR Inbox: Ignoring error
[2025-05-22T15:28:44.807+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:44.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:44.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:44.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:44.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:28:44.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:28:44.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:28:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:28:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:28:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:28:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:28:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:28:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:28:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:28:44.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:28:44.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:28:44.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:28:44.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:28:44.815+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:28:44.815+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:28:44.816+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:28:44.816+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:28:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:28:44.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:28:44.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:28:44.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:28:44.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:44.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:44.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:44.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:44.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:44.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:44.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:44.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:44.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:44.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:44.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:44.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:44.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:28:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:28:44.824+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:28:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:28:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:28:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:28:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:28:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:28:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:28:44.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:28:44.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:28:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:28:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:28:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:28:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:28:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:28:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:28:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:28:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:28:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:28:44.832+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:28:44.833+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:44 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:28:44.833+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:44.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:44.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:44.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:44.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:28:44.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:28:44.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:28:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:28:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:28:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:28:44.835+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:28:44.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:28:44.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:28:44.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:28:44.836+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:28:44.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:28:44.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:28:44.837+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:28:44.837+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:28:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:28:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:28:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:28:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:28:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:28:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:28:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:28:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:28:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:28:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:28:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:28:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:28:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:28:44.841+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:28:44.841+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:28:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:28:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:28:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:28:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:28:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:44.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:44.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:44.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:44.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:44.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:28:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:28:44.847+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:28:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:28:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:28:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:28:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:28:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:28:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:28:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:28:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:28:44.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:28:44.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:28:44.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:28:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:44.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:28:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:28:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:28:44.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:28:44.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:28:44.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:28:44.852+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:28:54.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:54 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:28:54.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:54 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:28:54.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:28:54.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:54 ERROR Inbox: Ignoring error
[2025-05-22T15:28:54.809+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:54.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:54.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:54.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:28:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:28:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:28:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:28:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:28:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:28:54.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:28:54.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:28:54.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:28:54.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:28:54.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:28:54.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:28:54.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:28:54.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:28:54.817+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:28:54.817+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:28:54.818+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:28:54.818+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:28:54.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:28:54.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:28:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:28:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:28:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:54.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:54.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:54.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:54.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:54.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:54.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:54.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:54.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:28:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:28:54.828+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:28:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:28:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:28:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:28:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:28:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:28:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:28:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:28:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:28:54.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:28:54.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:28:54.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:28:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:54.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:28:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:28:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:28:54.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:28:54.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:28:54.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:28:54.835+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:28:54.835+0000] {spark_submit.py:492} INFO - 25/05/22 15:28:54 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:28:54.836+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:54.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:54.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:54.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:54.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:28:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:28:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:28:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:28:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:28:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:28:54.838+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:28:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:28:54.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:28:54.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:28:54.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:28:54.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:28:54.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:28:54.839+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:28:54.839+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:28:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:28:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:28:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:28:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:28:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:28:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:28:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:28:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:28:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:28:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:28:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:28:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:28:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:28:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:28:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:28:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:28:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:28:54.843+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:28:54.843+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:28:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:28:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:28:54.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:28:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:28:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:54.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:54.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:28:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:28:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:28:54.848+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:28:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:28:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:28:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:28:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:28:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:28:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:28:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:28:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:28:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:28:54.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:28:54.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:28:54.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:28:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:28:54.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:28:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:28:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:28:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:28:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:28:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:28:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:28:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:28:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:28:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:28:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:28:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:28:54.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:28:54.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:28:54.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:28:54.853+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:29:04.797+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:04 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:29:04.798+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:04 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:29:04.799+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:29:04.799+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:04 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:29:04.800+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:04.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:04.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:29:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:29:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:29:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:29:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:29:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:29:04.802+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:29:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:29:04.803+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:29:04.803+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:29:04.803+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:29:04.804+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:29:04.804+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:29:04.804+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:29:04.804+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:04.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:04.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:04.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:04.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:29:04.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:29:04.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:29:04.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:29:04.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:29:04.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:29:04.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:29:04.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:29:04.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:29:04.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:29:04.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:29:04.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:29:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:29:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:29:04.808+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:29:04.808+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:29:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:29:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:29:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:29:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:29:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:04.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:04.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:29:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:29:04.813+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:29:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:29:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:29:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:29:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:29:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:29:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:29:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:29:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:29:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:29:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:29:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:29:04.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:04.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:04.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:04.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:04.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:04.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:04.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:04.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:04.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:04.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:29:04.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:29:04.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:29:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:29:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:29:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:29:04.819+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:29:04.819+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:04 ERROR Inbox: Ignoring error
[2025-05-22T15:29:04.819+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:29:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:29:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:29:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:29:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:29:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:29:04.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:29:04.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:29:04.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:29:04.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:29:04.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:29:04.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:29:04.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:29:04.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:29:04.822+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:29:04.822+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:29:04.822+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:29:04.822+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:29:04.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:29:04.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:29:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:29:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:29:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:04.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:04.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:29:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:29:04.826+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:29:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:29:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:29:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:29:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:29:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:29:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:29:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:29:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:29:04.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:29:04.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:29:04.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:29:04.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:04.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:04.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:04.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:04.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:29:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:29:04.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:29:04.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:29:04.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:29:04.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:29:04.834+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:29:14.798+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:14 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:29:14.798+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:14 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:29:14.799+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:29:14.799+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:14 ERROR Inbox: Ignoring error
[2025-05-22T15:29:14.799+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:14.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:14.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:14.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:14.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:29:14.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:29:14.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:29:14.800+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:29:14.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:29:14.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:29:14.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:29:14.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:29:14.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:29:14.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:29:14.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:29:14.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:29:14.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:29:14.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:29:14.802+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:29:14.802+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:29:14.802+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:29:14.802+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:29:14.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:29:14.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:29:14.802+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:29:14.802+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:29:14.802+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:14.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:14.803+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:14.803+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:14.803+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:14.803+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:14.803+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:14.803+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:14.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:14.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:14.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:14.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:14.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:14.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:14.804+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:14.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:14.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:14.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:14.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:14.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:14.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:14.805+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:14.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:14.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:29:14.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:29:14.806+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:14.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:29:14.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:29:14.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:29:14.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:29:14.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:29:14.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:29:14.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:14.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:14.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:14.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:14.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:29:14.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:29:14.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:29:14.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:29:14.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:29:14.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:29:14.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:14.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:14.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:14.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:14.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:14.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:14.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:14.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:14.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:14.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:14.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:29:14.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:29:14.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:29:14.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:29:14.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:29:14.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:29:14.810+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:29:14.811+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:14 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:29:14.811+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:29:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:29:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:29:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:29:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:29:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:29:14.812+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:29:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:29:14.812+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:29:14.812+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:29:14.813+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:29:14.813+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:29:14.813+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:29:14.813+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:29:14.813+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:29:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:29:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:29:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:29:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:29:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:29:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:29:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:29:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:29:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:29:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:29:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:29:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:29:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:29:14.815+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:29:14.816+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:29:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:29:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:29:14.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:29:14.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:29:14.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:14.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:14.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:14.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:14.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:14.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:29:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:29:14.821+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:29:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:29:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:29:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:29:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:29:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:29:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:29:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:29:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:29:14.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:29:14.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:29:14.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:29:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:14.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:29:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:29:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:29:14.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:29:14.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:29:14.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:29:14.824+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:29:24.801+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:24 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:29:24.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:24 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:29:24.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:29:24.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:24 ERROR Inbox: Ignoring error
[2025-05-22T15:29:24.807+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:24.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:24.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:24.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:24.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:29:24.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:29:24.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:29:24.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:29:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:29:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:29:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:29:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:29:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:29:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:29:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:29:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:29:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:29:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:29:24.813+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:29:24.814+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:29:24.814+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:29:24.814+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:29:24.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:29:24.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:29:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:29:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:29:24.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:24.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:24.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:24.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:24.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:24.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:24.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:24.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:24.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:24.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:24.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:24.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:24.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:24.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:24.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:29:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:29:24.823+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:29:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:29:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:29:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:29:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:29:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:29:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:29:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:29:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:29:24.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:29:24.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:29:24.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:29:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:24.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:29:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:29:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:29:24.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:29:24.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:29:24.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:29:24.828+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:29:24.828+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:24 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:29:24.828+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:24.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:24.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:24.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:24.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:29:24.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:29:24.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:29:24.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:29:24.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:29:24.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:29:24.830+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:24.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:29:24.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:29:24.830+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:29:24.830+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:29:24.830+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:29:24.831+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:29:24.831+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:29:24.831+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:29:24.831+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:24.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:24.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:24.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:24.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:29:24.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:29:24.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:29:24.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:29:24.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:29:24.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:29:24.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:29:24.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:29:24.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:29:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:29:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:29:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:29:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:29:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:29:24.835+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:29:24.835+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:29:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:29:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:29:24.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:29:24.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:29:24.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:24.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:24.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:24.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:24.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:24.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:24.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:24.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:24.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:24.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:24.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:24.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:24.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:24.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:24.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:24.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:24.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:24.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:24.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:24.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:24.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:24.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:24.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:29:24.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:29:24.840+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:24.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:29:24.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:29:24.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:29:24.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:29:24.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:29:24.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:29:24.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:24.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:24.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:24.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:24.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:29:24.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:29:24.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:29:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:29:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:29:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:29:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:24.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:29:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:29:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:29:24.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:29:24.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:29:24.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:29:24.845+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:29:34.800+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:34 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:29:34.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:34 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:29:34.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:29:34.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:34 ERROR Inbox: Ignoring error
[2025-05-22T15:29:34.805+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:34.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:34.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:34.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:34.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:29:34.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:29:34.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:29:34.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:29:34.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:29:34.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:29:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:29:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:29:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:29:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:29:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:29:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:29:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:29:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:29:34.813+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:29:34.813+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:29:34.813+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:29:34.814+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:29:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:29:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:29:34.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:29:34.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:29:34.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:34.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:34.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:34.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:34.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:34.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:29:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:29:34.823+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:29:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:29:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:29:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:29:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:29:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:29:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:29:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:29:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:29:34.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:29:34.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:29:34.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:29:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:34.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:29:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:29:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:29:34.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:29:34.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:29:34.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:29:34.833+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:29:34.833+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:34 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:29:34.834+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:34.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:34.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:29:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:29:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:29:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:29:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:29:34.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:29:34.840+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:34.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:29:34.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:29:34.841+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:29:34.842+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:29:34.842+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:29:34.842+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:29:34.842+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:29:34.843+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:29:34.843+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:34.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:34.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:34.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:34.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:29:34.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:29:34.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:29:34.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:29:34.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:29:34.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:29:34.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:29:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:29:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:29:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:29:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:29:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:29:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:29:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:29:34.847+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:29:34.848+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:29:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:29:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:29:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:29:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:29:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:34.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:34.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:29:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:29:34.854+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:29:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:29:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:29:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:29:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:29:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:29:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:29:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:29:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:29:34.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:29:34.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:29:34.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:29:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:34.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:29:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:29:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:29:34.860+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:29:34.860+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:29:34.860+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:29:34.860+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:29:44.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:44 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:29:44.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:44 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:29:44.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:29:44.809+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:44 ERROR Inbox: Ignoring error
[2025-05-22T15:29:44.809+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:44.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:29:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:29:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:29:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:29:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:29:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:29:44.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:29:44.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:29:44.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:29:44.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:29:44.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:29:44.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:29:44.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:29:44.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:29:44.820+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:29:44.821+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:29:44.821+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:29:44.821+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:29:44.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:29:44.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:29:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:29:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:29:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:44.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:44.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:44.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:29:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:29:44.831+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:29:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:29:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:29:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:29:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:29:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:29:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:29:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:29:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:29:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:29:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:29:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:29:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:44.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:29:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:29:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:29:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:29:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:29:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:29:44.839+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:29:44.839+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:44 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:29:44.839+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:29:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:29:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:29:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:29:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:29:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:29:44.841+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:29:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:29:44.842+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:29:44.842+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:29:44.842+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:29:44.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:29:44.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:29:44.843+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:29:44.843+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:29:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:29:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:29:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:29:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:29:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:29:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:29:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:29:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:29:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:29:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:29:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:29:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:29:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:29:44.847+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:29:44.847+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:29:44.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:29:44.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:29:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:29:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:29:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:44.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:44.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:29:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:29:44.852+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:29:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:29:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:29:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:29:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:29:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:29:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:29:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:29:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:29:44.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:29:44.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:29:44.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:29:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:44.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:29:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:29:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:29:44.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:29:44.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:29:44.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:29:44.857+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:29:54.800+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:54 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:29:54.801+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:54 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:29:54.801+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:29:54.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:54 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:29:54.802+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:54.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:54.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:54.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:54.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:29:54.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:29:54.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:29:54.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:29:54.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:29:54.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:29:54.805+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:54.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:29:54.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:29:54.805+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:29:54.805+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:29:54.806+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:29:54.806+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:29:54.806+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:29:54.806+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:29:54.806+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:54.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:54.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:54.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:54.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:29:54.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:29:54.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:29:54.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:29:54.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:29:54.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:29:54.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:29:54.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:29:54.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:29:54.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:29:54.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:29:54.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:29:54.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:29:54.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:29:54.810+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:29:54.810+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:29:54.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:29:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:29:54.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:29:54.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:29:54.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:54.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:54.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:54.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:54.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:54.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:54.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:54.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:54.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:54.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:54.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:54.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:54.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:54.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:54.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:54.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:54.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:54.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:54.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:54.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:54.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:54.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:29:54.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:29:54.815+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:54.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:29:54.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:29:54.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:29:54.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:29:54.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:29:54.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:29:54.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:54.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:54.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:54.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:54.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:29:54.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:29:54.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:29:54.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:29:54.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:29:54.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:29:54.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:54.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:29:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:29:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:29:54.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:29:54.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:29:54.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:29:54.821+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:29:54.821+0000] {spark_submit.py:492} INFO - 25/05/22 15:29:54 ERROR Inbox: Ignoring error
[2025-05-22T15:29:54.821+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:29:54.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:29:54.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:29:54.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:29:54.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:29:54.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:29:54.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:29:54.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:29:54.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:29:54.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:29:54.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:29:54.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:29:54.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:29:54.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:29:54.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:29:54.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:29:54.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:29:54.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:29:54.824+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:29:54.824+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:29:54.824+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:29:54.824+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:29:54.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:29:54.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:29:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:29:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:29:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:54.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:54.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:29:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:29:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:29:54.828+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:29:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:29:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:29:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:29:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:29:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:29:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:29:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:29:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:29:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:29:54.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:29:54.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:29:54.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:29:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:29:54.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:29:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:29:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:29:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:29:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:29:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:29:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:29:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:29:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:29:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:29:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:29:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:29:54.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:29:54.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:29:54.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:29:54.833+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:30:04.798+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:04 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:30:04.799+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:04 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:30:04.800+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:30:04.800+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:04 ERROR Inbox: Ignoring error
[2025-05-22T15:30:04.800+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:30:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:30:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:30:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:30:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:30:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:30:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:30:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:30:04.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:30:04.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:30:04.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:30:04.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:30:04.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:30:04.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:30:04.805+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:30:04.805+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:30:04.805+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:30:04.805+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:30:04.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:30:04.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:30:04.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:30:04.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:30:04.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:04.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:04.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:04.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:04.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:04.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:04.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:04.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:04.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:04.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:04.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:30:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:30:04.809+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:30:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:30:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:30:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:30:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:30:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:30:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:30:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:30:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:30:04.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:30:04.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:30:04.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:30:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:04.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:30:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:30:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:30:04.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:30:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:30:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:30:04.814+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:30:04.814+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:04 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:30:04.814+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:30:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:30:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:30:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:30:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:30:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:30:04.815+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:30:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:30:04.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:30:04.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:30:04.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:30:04.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:30:04.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:30:04.816+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:30:04.817+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:30:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:30:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:30:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:30:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:30:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:30:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:30:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:30:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:30:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:30:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:30:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:30:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:30:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:30:04.819+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:30:04.819+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:30:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:30:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:30:04.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:30:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:30:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:04.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:30:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:30:04.823+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:30:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:30:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:30:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:30:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:30:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:30:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:30:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:30:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:30:04.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:30:04.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:30:04.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:30:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:04.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:30:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:30:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:30:04.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:30:04.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:30:04.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:30:04.827+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:30:14.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:14 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:30:14.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:14 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:30:14.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:30:14.809+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:14 ERROR Inbox: Ignoring error
[2025-05-22T15:30:14.810+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:30:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:30:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:30:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:30:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:30:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:30:14.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:30:14.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:30:14.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:30:14.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:30:14.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:30:14.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:30:14.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:30:14.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:30:14.820+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:30:14.821+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:30:14.821+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:30:14.821+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:30:14.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:30:14.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:30:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:30:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:30:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:14.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:14.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:30:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:30:14.832+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:30:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:30:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:30:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:30:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:30:14.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:30:14.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:14.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:14.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:14.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:14.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:30:14.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:30:14.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:30:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:30:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:30:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:30:14.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:14.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:14.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:14.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:14.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:14.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:14.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:14.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:14.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:14.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:30:14.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:30:14.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:30:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:30:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:30:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:30:14.840+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:30:14.840+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:14 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:30:14.840+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:30:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:30:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:30:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:30:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:30:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:30:14.842+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:14.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:30:14.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:30:14.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:30:14.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:30:14.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:30:14.844+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:30:14.844+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:30:14.844+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:30:14.844+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:14.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:14.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:14.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:14.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:30:14.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:30:14.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:30:14.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:30:14.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:30:14.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:30:14.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:30:14.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:30:14.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:30:14.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:30:14.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:30:14.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:30:14.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:30:14.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:30:14.847+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:30:14.847+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:30:14.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:30:14.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:30:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:30:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:30:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:14.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:14.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:14.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:14.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:14.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:14.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:30:14.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:30:14.852+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:30:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:30:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:30:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:30:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:30:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:30:14.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:14.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:14.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:14.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:14.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:30:14.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:30:14.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:30:14.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:30:14.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:30:14.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:30:14.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:14.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:14.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:14.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:14.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:14.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:14.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:14.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:14.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:14.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:14.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:30:14.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:30:14.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:30:14.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:30:14.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:30:14.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:30:14.857+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:30:24.801+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:24 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:30:24.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:24 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:30:24.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:30:24.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:24 ERROR Inbox: Ignoring error
[2025-05-22T15:30:24.803+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:24.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:24.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:24.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:24.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:30:24.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:30:24.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:30:24.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:30:24.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:30:24.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:30:24.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:30:24.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:30:24.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:30:24.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:30:24.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:30:24.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:30:24.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:30:24.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:30:24.807+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:30:24.807+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:30:24.807+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:30:24.807+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:30:24.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:30:24.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:30:24.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:30:24.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:30:24.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:24.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:24.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:24.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:24.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:24.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:24.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:24.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:24.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:24.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:24.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:24.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:24.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:24.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:24.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:24.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:24.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:24.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:24.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:24.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:24.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:24.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:24.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:30:24.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:30:24.813+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:24.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:30:24.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:30:24.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:30:24.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:30:24.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:30:24.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:30:24.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:24.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:30:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:30:24.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:30:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:30:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:30:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:30:24.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:24.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:24.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:24.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:24.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:30:24.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:30:24.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:30:24.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:30:24.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:30:24.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:30:24.819+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:30:24.819+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:24 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:30:24.819+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:24.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:24.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:24.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:24.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:30:24.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:30:24.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:30:24.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:30:24.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:30:24.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:30:24.821+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:24.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:30:24.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:30:24.821+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:30:24.821+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:30:24.822+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:30:24.822+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:30:24.822+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:30:24.822+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:30:24.822+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:24.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:24.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:24.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:24.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:30:24.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:30:24.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:30:24.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:30:24.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:30:24.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:30:24.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:30:24.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:30:24.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:30:24.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:30:24.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:30:24.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:30:24.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:30:24.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:30:24.825+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:30:24.825+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:30:24.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:30:24.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:30:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:30:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:30:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:24.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:24.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:30:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:30:24.829+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:30:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:30:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:30:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:30:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:30:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:30:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:30:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:30:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:30:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:30:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:30:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:30:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:30:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:30:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:30:24.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:30:24.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:30:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:30:24.834+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:30:34.800+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:34 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:30:34.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:34 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:30:34.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:30:34.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:34 ERROR Inbox: Ignoring error
[2025-05-22T15:30:34.805+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:34.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:34.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:34.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:34.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:30:34.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:30:34.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:30:34.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:30:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:30:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:30:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:30:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:30:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:30:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:30:34.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:30:34.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:30:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:30:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:30:34.815+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:30:34.815+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:30:34.815+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:30:34.816+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:30:34.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:30:34.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:30:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:30:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:30:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:34.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:34.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:30:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:30:34.828+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:30:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:30:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:30:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:30:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:30:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:30:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:30:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:30:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:30:34.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:30:34.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:30:34.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:30:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:34.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:30:34.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:30:34.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:30:34.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:30:34.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:30:34.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:30:34.836+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:30:34.836+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:34 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:30:34.836+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:34.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:34.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:30:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:30:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:30:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:30:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:30:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:30:34.838+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:30:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:30:34.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:30:34.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:30:34.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:30:34.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:30:34.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:30:34.840+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:30:34.840+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:34.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:34.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:34.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:34.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:30:34.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:30:34.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:30:34.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:30:34.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:30:34.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:30:34.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:30:34.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:30:34.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:30:34.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:30:34.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:30:34.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:30:34.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:30:34.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:30:34.843+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:30:34.844+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:30:34.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:30:34.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:30:34.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:30:34.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:30:34.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:34.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:34.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:34.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:34.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:34.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:34.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:34.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:34.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:34.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:34.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:34.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:34.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:30:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:30:34.849+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:30:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:30:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:30:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:30:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:30:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:30:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:30:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:30:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:30:34.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:30:34.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:30:34.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:30:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:34.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:30:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:30:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:30:34.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:30:34.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:30:34.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:30:34.854+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:30:44.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:44 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:30:44.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:44 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:30:44.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:30:44.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:44 ERROR Inbox: Ignoring error
[2025-05-22T15:30:44.808+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:44.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:44.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:44.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:44.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:30:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:30:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:30:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:30:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:30:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:30:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:30:44.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:30:44.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:30:44.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:30:44.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:30:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:30:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:30:44.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:30:44.817+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:30:44.818+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:30:44.818+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:30:44.819+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:30:44.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:30:44.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:30:44.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:30:44.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:30:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:44.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:44.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:44.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:44.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:44.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:44.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:30:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:30:44.829+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:30:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:30:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:30:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:30:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:30:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:30:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:30:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:30:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:30:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:30:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:30:44.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:30:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:44.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:30:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:30:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:30:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:30:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:30:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:30:44.836+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:30:44.836+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:44 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:30:44.836+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:44.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:44.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:44.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:44.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:30:44.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:30:44.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:30:44.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:30:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:30:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:30:44.838+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:30:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:30:44.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:30:44.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:30:44.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:30:44.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:30:44.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:30:44.839+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:30:44.840+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:30:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:30:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:30:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:30:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:30:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:30:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:30:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:30:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:30:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:30:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:30:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:30:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:30:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:30:44.843+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:30:44.843+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:30:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:30:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:30:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:30:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:30:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:44.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:44.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:30:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:30:44.848+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:30:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:30:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:30:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:30:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:30:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:30:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:30:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:30:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:30:44.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:30:44.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:30:44.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:30:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:44.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:30:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:30:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:30:44.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:30:44.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:30:44.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:30:44.853+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:30:54.801+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:54 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:30:54.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:54 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:30:54.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:30:54.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:54 ERROR Inbox: Ignoring error
[2025-05-22T15:30:54.807+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:54.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:54.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:54.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:54.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:30:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:30:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:30:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:30:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:30:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:30:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:30:54.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:30:54.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:30:54.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:30:54.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:30:54.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:30:54.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:30:54.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:30:54.817+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:30:54.818+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:30:54.818+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:30:54.819+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:30:54.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:30:54.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:30:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:30:54.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:30:54.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:54.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:54.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:54.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:54.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:30:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:30:54.829+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:30:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:30:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:30:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:30:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:30:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:30:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:30:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:30:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:30:54.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:30:54.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:30:54.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:30:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:54.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:30:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:30:54.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:30:54.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:30:54.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:30:54.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:30:54.836+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:30:54.837+0000] {spark_submit.py:492} INFO - 25/05/22 15:30:54 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:30:54.837+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:30:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:30:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:30:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:30:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:30:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:30:54.839+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:30:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:30:54.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:30:54.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:30:54.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:30:54.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:30:54.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:30:54.840+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:30:54.841+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:30:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:30:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:30:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:30:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:30:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:30:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:30:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:30:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:30:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:30:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:30:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:30:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:30:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:30:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:30:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:30:54.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:30:54.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:30:54.844+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:30:54.844+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:30:54.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:30:54.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:30:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:30:54.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:30:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:54.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:54.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:30:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:30:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:30:54.848+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:30:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:30:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:30:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:30:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:30:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:30:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:30:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:30:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:30:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:30:54.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:30:54.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:30:54.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:30:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:30:54.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:30:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:30:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:30:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:30:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:30:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:30:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:30:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:30:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:30:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:30:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:30:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:30:54.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:30:54.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:30:54.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:30:54.852+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:31:04.798+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:04 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:31:04.799+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:04 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:31:04.800+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:31:04.800+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:04 ERROR Inbox: Ignoring error
[2025-05-22T15:31:04.800+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:04.801+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:31:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:31:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:31:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:31:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:31:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:31:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:31:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:31:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:31:04.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:31:04.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:31:04.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:31:04.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:31:04.805+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:31:04.805+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:31:04.805+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:31:04.805+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:31:04.806+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:31:04.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:31:04.806+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:31:04.806+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:31:04.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:31:04.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:04.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:04.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:04.807+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:04.808+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:04.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:31:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:31:04.812+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:31:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:31:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:31:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:31:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:31:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:31:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:31:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:31:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:31:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:31:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:31:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:31:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:04.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:04.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:04.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:04.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:04.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:04.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:04.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:04.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:04.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:31:04.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:31:04.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:31:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:31:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:31:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:31:04.818+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:31:04.818+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:04 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:31:04.818+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:31:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:31:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:31:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:31:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:31:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:31:04.820+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:31:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:31:04.820+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:31:04.821+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:31:04.821+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:31:04.821+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:31:04.821+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:31:04.821+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:31:04.821+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:04.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:04.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:04.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:04.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:31:04.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:31:04.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:31:04.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:31:04.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:31:04.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:31:04.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:31:04.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:31:04.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:31:04.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:31:04.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:31:04.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:31:04.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:31:04.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:31:04.824+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:31:04.824+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:31:04.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:31:04.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:31:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:31:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:31:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:04.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:04.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:04.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:31:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:31:04.829+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:31:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:31:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:31:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:31:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:31:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:31:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:31:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:31:04.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:31:04.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:31:04.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:31:04.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:31:04.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:04.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:04.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:04.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:31:04.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:31:04.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:31:04.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:31:04.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:31:04.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:31:04.833+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:31:14.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:14 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:31:14.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:14 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:31:14.809+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:31:14.809+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:14 ERROR Inbox: Ignoring error
[2025-05-22T15:31:14.810+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:31:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:31:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:31:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:31:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:31:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:31:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:31:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:31:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:31:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:31:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:31:14.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:31:14.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:31:14.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:31:14.818+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:31:14.818+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:31:14.818+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:31:14.819+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:31:14.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:31:14.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:31:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:31:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:31:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:14.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:14.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:31:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:31:14.828+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:31:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:31:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:31:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:31:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:31:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:31:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:31:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:31:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:31:14.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:31:14.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:31:14.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:31:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:14.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:14.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:14.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:14.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:14.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:14.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:14.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:31:14.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:31:14.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:31:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:31:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:31:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:31:14.836+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:31:14.837+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:14 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:31:14.837+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:31:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:31:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:31:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:31:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:31:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:31:14.839+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:31:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:31:14.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:31:14.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:31:14.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:31:14.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:31:14.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:31:14.841+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:31:14.841+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:31:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:31:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:31:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:31:14.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:31:14.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:31:14.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:31:14.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:31:14.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:31:14.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:31:14.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:31:14.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:31:14.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:31:14.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:31:14.845+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:31:14.845+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:31:14.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:31:14.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:31:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:31:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:31:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:14.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:14.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:31:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:31:14.850+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:31:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:31:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:31:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:31:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:31:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:31:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:31:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:31:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:31:14.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:31:14.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:31:14.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:31:14.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:14.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:14.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:14.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:14.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:31:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:31:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:31:14.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:31:14.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:31:14.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:31:14.854+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:31:24.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:24 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:31:24.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:24 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:31:24.810+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:31:24.811+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:24 ERROR Inbox: Ignoring error
[2025-05-22T15:31:24.811+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:31:24.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:31:24.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:31:24.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:31:24.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:31:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:31:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:31:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:31:24.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:31:24.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:31:24.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:31:24.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:31:24.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:31:24.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:31:24.818+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:31:24.819+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:31:24.819+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:31:24.819+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:31:24.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:31:24.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:31:24.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:31:24.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:31:24.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:24.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:24.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:24.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:24.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:24.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:31:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:31:24.826+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:31:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:31:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:31:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:31:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:31:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:31:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:31:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:31:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:31:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:31:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:31:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:31:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:24.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:31:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:31:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:31:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:31:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:31:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:31:24.835+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:31:24.835+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:24 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:31:24.835+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:31:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:31:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:31:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:31:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:31:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:31:24.837+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:31:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:31:24.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:31:24.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:31:24.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:31:24.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:31:24.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:31:24.839+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:31:24.839+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:31:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:31:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:31:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:31:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:31:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:31:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:31:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:31:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:31:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:31:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:31:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:31:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:31:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:31:24.842+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:31:24.842+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:31:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:31:24.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:31:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:31:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:31:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:24.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:24.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:31:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:31:24.848+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:31:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:31:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:31:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:31:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:31:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:31:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:31:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:31:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:31:24.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:31:24.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:31:24.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:31:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:24.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:24.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:31:24.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:31:24.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:31:24.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:31:24.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:31:24.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:31:24.854+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:31:34.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:34 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:31:34.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:34 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:31:34.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:31:34.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:34 ERROR Inbox: Ignoring error
[2025-05-22T15:31:34.808+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:34.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:34.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:34.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:34.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:31:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:31:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:31:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:31:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:31:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:31:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:31:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:31:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:31:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:31:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:31:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:31:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:31:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:31:34.811+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:31:34.811+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:31:34.811+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:31:34.811+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:31:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:31:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:31:34.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:31:34.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:31:34.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:34.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:34.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:34.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:34.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:34.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:34.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:34.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:34.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:34.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:34.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:34.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:34.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:34.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:34.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:34.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:34.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:34.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:34.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:34.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:34.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:34.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:34.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:31:34.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:31:34.815+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:34.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:31:34.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:31:34.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:31:34.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:31:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:31:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:31:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:31:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:31:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:31:34.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:31:34.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:31:34.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:31:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:34.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:31:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:31:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:31:34.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:31:34.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:31:34.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:31:34.820+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:31:34.820+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:34 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:31:34.820+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:34.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:34.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:34.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:34.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:31:34.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:31:34.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:31:34.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:31:34.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:31:34.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:31:34.823+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:34.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:31:34.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:31:34.823+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:31:34.823+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:31:34.823+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:31:34.824+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:31:34.824+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:31:34.824+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:31:34.824+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:34.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:34.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:34.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:34.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:31:34.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:31:34.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:31:34.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:31:34.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:31:34.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:31:34.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:31:34.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:31:34.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:31:34.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:31:34.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:31:34.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:31:34.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:31:34.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:31:34.828+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:31:34.828+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:31:34.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:31:34.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:31:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:31:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:31:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:34.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:34.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:31:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:31:34.831+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:31:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:31:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:31:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:31:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:31:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:31:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:31:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:31:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:31:34.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:31:34.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:31:34.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:31:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:34.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:31:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:31:34.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:31:34.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:31:34.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:31:34.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:31:34.835+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:31:44.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:44 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:31:44.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:44 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:31:44.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:31:44.809+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:44 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:31:44.810+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:44.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:44.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:31:44.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:31:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:31:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:31:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:31:44.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:31:44.817+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:44.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:31:44.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:31:44.820+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:31:44.821+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:31:44.821+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:31:44.822+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:31:44.822+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:31:44.822+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:31:44.823+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:44.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:44.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:44.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:44.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:31:44.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:31:44.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:31:44.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:31:44.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:31:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:31:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:31:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:31:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:31:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:31:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:31:44.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:31:44.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:31:44.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:31:44.829+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:31:44.830+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:31:44.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:31:44.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:31:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:31:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:31:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:44.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:44.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:31:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:31:44.837+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:31:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:31:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:31:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:31:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:31:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:31:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:44.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:44.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:44.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:31:44.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:31:44.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:31:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:31:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:31:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:31:44.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:44.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:44.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:44.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:44.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:44.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:44.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:31:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:31:44.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:31:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:31:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:31:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:31:44.843+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:31:44.843+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:44 ERROR Inbox: Ignoring error
[2025-05-22T15:31:44.844+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:31:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:31:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:31:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:31:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:31:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:31:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:31:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:31:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:31:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:31:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:31:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:31:44.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:31:44.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:31:44.847+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:31:44.847+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:31:44.847+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:31:44.847+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:31:44.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:31:44.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:31:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:31:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:31:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:44.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:44.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:31:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:31:44.852+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:31:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:31:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:31:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:31:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:31:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:31:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:31:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:31:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:31:44.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:31:44.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:31:44.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:31:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:44.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:31:44.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:31:44.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:31:44.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:31:44.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:31:44.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:31:44.857+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:31:54.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:54 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:31:54.809+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:54 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:31:54.810+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:31:54.811+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:54 ERROR Inbox: Ignoring error
[2025-05-22T15:31:54.812+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:54.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:54.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:31:54.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:31:54.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:31:54.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:31:54.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:31:54.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:31:54.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:31:54.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:31:54.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:31:54.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:31:54.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:31:54.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:31:54.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:31:54.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:31:54.821+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:31:54.822+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:31:54.822+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:31:54.823+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:31:54.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:31:54.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:31:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:31:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:31:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:54.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:54.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:31:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:31:54.833+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:31:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:31:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:31:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:31:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:31:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:31:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:31:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:31:54.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:31:54.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:31:54.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:31:54.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:31:54.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:54.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:54.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:54.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:54.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:54.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:54.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:54.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:54.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:54.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:31:54.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:31:54.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:31:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:31:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:31:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:31:54.840+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:31:54.840+0000] {spark_submit.py:492} INFO - 25/05/22 15:31:54 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:31:54.841+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:31:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:31:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:31:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:31:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:31:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:31:54.843+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:31:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:31:54.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:31:54.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:31:54.844+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:31:54.844+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:31:54.844+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:31:54.844+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:31:54.845+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:31:54.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:31:54.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:31:54.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:31:54.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:31:54.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:31:54.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:31:54.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:31:54.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:31:54.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:31:54.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:31:54.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:31:54.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:31:54.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:31:54.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:31:54.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:31:54.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:31:54.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:31:54.848+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:31:54.848+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:31:54.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:31:54.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:31:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:31:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:31:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:54.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:54.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:31:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:31:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:31:54.853+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:31:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:31:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:31:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:31:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:31:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:31:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:31:54.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:54.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:54.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:54.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:54.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:31:54.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:31:54.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:31:54.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:31:54.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:31:54.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:31:54.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:31:54.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:31:54.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:31:54.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:31:54.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:31:54.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:31:54.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:31:54.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:31:54.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:31:54.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:31:54.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:31:54.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:31:54.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:31:54.858+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:31:54.858+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:31:54.859+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:31:54.859+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:32:04.801+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:04 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:32:04.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:04 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:32:04.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:32:04.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:04 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:32:04.802+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:04.802+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:32:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:32:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:32:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:32:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:32:04.803+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:32:04.803+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:04.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:32:04.804+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:32:04.804+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:32:04.804+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:32:04.804+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:32:04.804+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:32:04.804+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:32:04.807+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:32:04.807+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:04.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:04.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:04.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:04.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:32:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:32:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:32:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:32:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:32:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:32:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:32:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:32:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:32:04.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:32:04.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:32:04.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:32:04.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:32:04.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:32:04.809+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:32:04.809+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:32:04.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:32:04.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:32:04.809+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:32:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:32:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:04.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:04.810+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:04.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:04.811+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:32:04.812+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:32:04.813+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:32:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:32:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:32:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:32:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:32:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:32:04.813+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:32:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:32:04.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:32:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:32:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:32:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:32:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:04.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:04.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:04.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:32:04.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:32:04.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:32:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:32:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:32:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:32:04.816+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:32:04.816+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:04 ERROR Inbox: Ignoring error
[2025-05-22T15:32:04.817+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:32:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:32:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:32:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:32:04.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:32:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:32:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:32:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:32:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:32:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:32:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:32:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:32:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:32:04.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:32:04.819+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:32:04.819+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:32:04.819+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:32:04.819+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:32:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:32:04.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:32:04.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:32:04.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:32:04.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:04.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:04.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:04.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:04.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:32:04.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:32:04.822+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:32:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:32:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:32:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:32:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:32:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:32:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:04.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:32:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:32:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:32:04.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:32:04.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:32:04.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:32:04.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:04.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:04.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:32:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:32:04.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:32:04.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:32:04.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:32:04.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:32:04.826+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:32:14.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:14 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:32:14.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:14 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:32:14.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:32:14.809+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:14 ERROR Inbox: Ignoring error
[2025-05-22T15:32:14.809+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:14.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:14.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:32:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:32:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:32:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:32:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:32:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:32:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:32:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:32:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:32:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:32:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:32:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:32:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:32:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:32:14.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:32:14.817+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:32:14.817+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:32:14.817+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:32:14.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:32:14.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:32:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:32:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:32:14.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:14.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:14.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:14.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:14.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:32:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:32:14.826+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:32:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:32:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:32:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:32:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:32:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:32:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:32:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:32:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:32:14.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:32:14.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:32:14.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:32:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:14.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:32:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:32:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:32:14.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:32:14.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:32:14.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:32:14.833+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:32:14.834+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:14 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:32:14.834+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:32:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:32:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:32:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:32:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:32:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:32:14.836+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:32:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:32:14.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:32:14.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:32:14.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:32:14.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:32:14.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:32:14.838+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:32:14.838+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:14.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:32:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:32:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:32:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:32:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:32:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:32:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:32:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:32:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:32:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:32:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:32:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:32:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:32:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:32:14.841+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:32:14.842+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:32:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:32:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:32:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:32:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:32:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:14.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:14.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:32:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:32:14.847+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:32:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:32:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:32:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:32:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:32:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:32:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:32:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:32:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:32:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:32:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:32:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:32:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:14.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:32:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:32:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:32:14.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:32:14.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:32:14.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:32:14.852+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:32:24.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:24 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:32:24.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:24 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:32:24.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:32:24.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:24 ERROR Inbox: Ignoring error
[2025-05-22T15:32:24.809+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:24.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:32:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:32:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:32:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:32:24.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:32:24.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:32:24.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:32:24.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:32:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:32:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:32:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:32:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:32:24.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:32:24.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:32:24.817+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:32:24.818+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:32:24.818+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:32:24.818+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:32:24.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:32:24.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:32:24.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:32:24.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:32:24.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:24.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:24.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:24.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:32:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:32:24.828+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:32:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:32:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:32:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:32:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:32:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:32:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:32:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:32:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:32:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:32:24.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:32:24.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:32:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:24.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:32:24.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:32:24.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:32:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:32:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:32:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:32:24.836+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:32:24.836+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:24 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:32:24.836+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:32:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:32:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:32:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:32:24.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:32:24.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:32:24.838+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:24.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:32:24.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:32:24.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:32:24.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:32:24.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:32:24.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:32:24.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:32:24.839+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:32:24.840+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:32:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:32:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:32:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:32:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:32:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:32:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:32:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:32:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:32:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:32:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:32:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:32:24.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:32:24.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:32:24.843+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:32:24.843+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:32:24.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:32:24.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:32:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:32:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:32:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:24.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:24.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:32:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:32:24.848+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:32:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:32:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:32:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:32:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:32:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:32:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:32:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:32:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:32:24.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:32:24.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:32:24.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:32:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:24.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:32:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:32:24.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:32:24.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:32:24.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:32:24.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:32:24.853+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:32:34.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:34 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:32:34.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:34 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:32:34.810+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:32:34.811+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:34 ERROR Inbox: Ignoring error
[2025-05-22T15:32:34.812+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:34.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:34.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:32:34.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:32:34.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:32:34.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:32:34.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:32:34.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:32:34.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:32:34.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:32:34.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:32:34.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:32:34.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:32:34.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:32:34.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:32:34.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:32:34.821+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:32:34.821+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:32:34.822+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:32:34.822+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:32:34.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:32:34.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:32:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:32:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:32:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:34.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:34.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:34.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:34.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:34.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:32:34.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:32:34.835+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:34.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:32:34.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:32:34.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:32:34.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:32:34.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:32:34.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:32:34.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:34.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:34.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:34.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:34.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:32:34.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:32:34.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:32:34.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:32:34.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:32:34.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:32:34.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:34.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:34.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:34.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:34.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:34.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:34.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:32:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:32:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:32:34.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:32:34.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:32:34.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:32:34.844+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:32:34.845+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:34 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:32:34.845+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:34.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:34.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:32:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:32:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:32:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:32:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:32:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:32:34.848+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:32:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:32:34.848+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:32:34.849+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:32:34.849+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:32:34.849+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:32:34.849+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:32:34.850+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:32:34.850+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:34.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:34.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:34.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:34.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:32:34.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:32:34.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:32:34.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:32:34.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:32:34.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:32:34.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:32:34.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:32:34.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:32:34.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:32:34.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:32:34.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:32:34.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:32:34.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:32:34.854+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:32:34.854+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:32:34.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:32:34.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:32:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:32:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:32:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:34.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:34.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:32:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:32:34.859+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:34.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:32:34.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:32:34.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:32:34.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:32:34.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:32:34.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:32:34.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:34.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:34.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:34.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:34.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:32:34.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:32:34.862+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:32:34.862+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:32:34.862+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:32:34.862+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:32:34.862+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:34.862+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:34.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:34.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:34.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:34.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:34.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:34.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:34.864+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:34.864+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:34.864+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:32:34.864+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:32:34.864+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:32:34.864+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:32:34.865+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:32:34.865+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:32:34.865+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:32:44.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:44 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:32:44.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:44 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:32:44.809+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:32:44.810+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:44 ERROR Inbox: Ignoring error
[2025-05-22T15:32:44.811+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:32:44.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:32:44.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:32:44.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:32:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:32:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:32:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:32:44.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:32:44.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:32:44.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:32:44.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:32:44.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:32:44.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:32:44.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:32:44.820+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:32:44.820+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:32:44.821+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:32:44.821+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:32:44.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:32:44.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:32:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:32:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:32:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:44.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:44.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:44.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:44.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:32:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:32:44.831+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:32:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:32:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:32:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:32:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:32:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:32:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:32:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:32:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:32:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:32:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:32:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:32:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:44.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:32:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:32:44.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:32:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:32:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:32:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:32:44.839+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:32:44.839+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:44 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:32:44.839+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:32:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:32:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:32:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:32:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:32:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:32:44.841+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:44.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:32:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:32:44.842+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:32:44.842+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:32:44.842+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:32:44.842+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:32:44.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:32:44.843+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:32:44.843+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:32:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:32:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:32:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:32:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:32:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:32:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:32:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:32:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:32:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:32:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:32:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:32:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:32:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:32:44.846+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:32:44.847+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:32:44.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:32:44.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:32:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:32:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:32:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:44.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:44.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:32:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:32:44.852+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:32:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:32:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:32:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:32:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:32:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:32:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:32:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:32:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:32:44.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:32:44.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:32:44.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:32:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:44.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:32:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:32:44.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:32:44.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:32:44.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:32:44.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:32:44.857+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:32:54.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:54 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:32:54.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:54 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:32:54.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:32:54.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:54 ERROR Inbox: Ignoring error
[2025-05-22T15:32:54.808+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:54.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:54.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:54.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:54.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:32:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:32:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:32:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:32:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:32:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:32:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:32:54.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:32:54.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:32:54.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:32:54.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:32:54.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:32:54.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:32:54.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:32:54.817+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:32:54.817+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:32:54.818+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:32:54.818+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:32:54.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:32:54.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:32:54.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:32:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:32:54.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:54.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:54.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:54.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:54.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:54.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:32:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:32:54.829+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:32:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:32:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:32:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:32:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:32:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:32:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:32:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:32:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:32:54.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:32:54.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:32:54.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:32:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:54.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:32:54.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:32:54.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:32:54.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:32:54.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:32:54.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:32:54.837+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:32:54.837+0000] {spark_submit.py:492} INFO - 25/05/22 15:32:54 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:32:54.837+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:32:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:32:54.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:32:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:32:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:32:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:32:54.839+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:32:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:32:54.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:32:54.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:32:54.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:32:54.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:32:54.841+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:32:54.841+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:32:54.841+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:32:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:32:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:32:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:32:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:32:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:32:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:32:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:32:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:32:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:32:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:32:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:32:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:32:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:32:54.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:32:54.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:32:54.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:32:54.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:32:54.844+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:32:54.845+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:32:54.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:32:54.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:32:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:32:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:32:54.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:54.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:54.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:54.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:54.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:32:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:32:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:32:54.850+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:32:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:32:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:32:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:32:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:32:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:32:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:32:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:32:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:32:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:32:54.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:32:54.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:32:54.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:32:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:32:54.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:32:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:32:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:32:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:32:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:32:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:32:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:32:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:32:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:32:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:32:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:32:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:32:54.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:32:54.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:32:54.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:32:54.855+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:33:04.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:04 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:33:04.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:04 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:33:04.810+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:33:04.811+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:04 ERROR Inbox: Ignoring error
[2025-05-22T15:33:04.813+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:04.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:04.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:04.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:04.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:33:04.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:33:04.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:33:04.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:33:04.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:33:04.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:33:04.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:33:04.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:33:04.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:33:04.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:33:04.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:33:04.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:33:04.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:33:04.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:33:04.826+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:33:04.826+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:33:04.827+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:33:04.827+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:33:04.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:33:04.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:33:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:33:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:33:04.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:04.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:04.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:04.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:04.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:04.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:04.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:04.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:04.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:04.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:04.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:04.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:04.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:04.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:04.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:04.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:04.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:04.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:04.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:04.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:33:04.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:33:04.837+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:04.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:33:04.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:33:04.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:33:04.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:33:04.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:33:04.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:33:04.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:04.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:04.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:04.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:04.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:33:04.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:33:04.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:33:04.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:33:04.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:33:04.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:33:04.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:04.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:04.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:04.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:04.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:04.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:04.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:04.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:04.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:04.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:04.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:33:04.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:33:04.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:33:04.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:33:04.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:33:04.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:33:04.848+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:33:04.848+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:04 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:33:04.848+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:04.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:04.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:04.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:04.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:33:04.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:33:04.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:33:04.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:33:04.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:33:04.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:33:04.851+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:04.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:33:04.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:33:04.852+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:33:04.852+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:33:04.852+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:33:04.852+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:33:04.852+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:33:04.853+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:33:04.853+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:04.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:04.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:04.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:04.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:33:04.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:33:04.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:33:04.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:33:04.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:33:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:33:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:33:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:33:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:33:04.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:33:04.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:33:04.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:33:04.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:33:04.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:33:04.857+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:33:04.857+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:33:04.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:33:04.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:33:04.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:33:04.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:33:04.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:04.858+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:04.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:04.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:04.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:04.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:04.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:04.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:04.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:04.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:04.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:04.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:04.860+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:04.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:04.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:04.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:04.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:04.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:04.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:04.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:04.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:04.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:04.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:04.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:33:04.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:33:04.862+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:04.862+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:33:04.862+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:33:04.862+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:33:04.862+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:33:04.862+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:33:04.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:33:04.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:04.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:04.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:04.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:04.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:33:04.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:33:04.864+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:33:04.864+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:33:04.864+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:33:04.864+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:33:04.864+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:04.864+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:04.864+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:04.864+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:04.865+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:04.865+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:04.865+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:04.865+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:04.865+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:04.865+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:04.865+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:33:04.866+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:33:04.866+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:33:04.866+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:33:04.866+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:33:04.866+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:33:04.866+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:33:14.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:14 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:33:14.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:14 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:33:14.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:33:14.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:14 ERROR Inbox: Ignoring error
[2025-05-22T15:33:14.809+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:14.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:14.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:14.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:33:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:33:14.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:33:14.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:33:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:33:14.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:33:14.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:33:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:33:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:33:14.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:33:14.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:33:14.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:33:14.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:33:14.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:33:14.819+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:33:14.819+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:33:14.820+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:33:14.820+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:33:14.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:33:14.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:33:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:33:14.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:33:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:14.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:14.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:14.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:14.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:14.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:14.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:14.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:33:14.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:33:14.828+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:33:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:33:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:33:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:33:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:33:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:33:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:33:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:33:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:33:14.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:33:14.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:33:14.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:33:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:14.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:33:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:33:14.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:33:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:33:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:33:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:33:14.834+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:33:14.835+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:14 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:33:14.835+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:14.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:33:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:33:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:33:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:33:14.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:33:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:33:14.837+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:33:14.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:33:14.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:33:14.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:33:14.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:33:14.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:33:14.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:33:14.839+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:33:14.839+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:14.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:33:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:33:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:33:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:33:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:33:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:33:14.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:33:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:33:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:33:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:33:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:33:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:33:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:33:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:33:14.842+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:33:14.842+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:33:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:33:14.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:33:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:33:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:33:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:14.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:14.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:14.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:14.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:33:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:33:14.847+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:33:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:33:14.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:33:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:33:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:33:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:33:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:14.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:33:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:33:14.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:33:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:33:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:33:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:33:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:14.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:14.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:33:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:33:14.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:33:14.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:33:14.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:33:14.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:33:14.852+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:33:24.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:24 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:33:24.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:24 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:33:24.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:33:24.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:24 ERROR Inbox: Ignoring error
[2025-05-22T15:33:24.808+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:24.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:24.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:24.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:33:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:33:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:33:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:33:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:33:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:33:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:33:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:33:24.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:33:24.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:33:24.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:33:24.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:33:24.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:33:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:33:24.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:33:24.816+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:33:24.817+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:33:24.817+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:33:24.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:33:24.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:33:24.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:33:24.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:33:24.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:24.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:24.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:24.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:24.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:24.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:24.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:33:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:33:24.827+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:33:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:33:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:33:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:33:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:33:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:33:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:33:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:33:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:33:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:33:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:33:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:33:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:33:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:33:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:33:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:33:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:33:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:33:24.835+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:33:24.835+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:24 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:33:24.835+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:33:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:33:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:33:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:33:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:33:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:33:24.837+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:33:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:33:24.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:33:24.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:33:24.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:33:24.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:33:24.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:33:24.839+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:33:24.839+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:33:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:33:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:33:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:33:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:33:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:33:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:33:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:33:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:33:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:33:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:33:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:33:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:33:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:33:24.842+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:33:24.842+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:33:24.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:33:24.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:33:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:33:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:33:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:24.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:24.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:33:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:33:24.847+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:33:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:33:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:33:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:33:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:33:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:33:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:33:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:33:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:33:24.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:33:24.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:33:24.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:33:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:24.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:33:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:33:24.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:33:24.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:33:24.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:33:24.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:33:24.852+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:33:34.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:34 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:33:34.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:34 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:33:34.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:33:34.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:34 ERROR Inbox: Ignoring error
[2025-05-22T15:33:34.807+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:34.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:34.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:34.807+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:34.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:33:34.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:33:34.808+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:33:34.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:33:34.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:33:34.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:33:34.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:33:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:33:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:33:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:33:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:33:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:33:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:33:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:33:34.812+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:33:34.813+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:33:34.813+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:33:34.813+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:33:34.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:33:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:33:34.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:33:34.814+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:33:34.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:34.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:34.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:34.815+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:34.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:34.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:34.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:34.816+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:34.817+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:34.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:34.818+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:33:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:33:34.821+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:33:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:33:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:33:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:33:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:33:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:33:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:33:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:33:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:33:34.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:33:34.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:33:34.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:33:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:34.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:33:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:33:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:33:34.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:33:34.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:33:34.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:33:34.830+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:33:34.830+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:34 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:33:34.830+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:34.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:34.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:34.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:34.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:33:34.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:33:34.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:33:34.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:33:34.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:33:34.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:33:34.833+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:34.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:33:34.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:33:34.833+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:33:34.833+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:33:34.834+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:33:34.834+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:33:34.834+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:33:34.834+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:33:34.835+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:34.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:34.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:34.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:34.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:33:34.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:33:34.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:33:34.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:33:34.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:33:34.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:33:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:33:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:33:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:33:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:33:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:33:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:33:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:33:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:33:34.838+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:33:34.838+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:33:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:33:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:33:34.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:33:34.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:33:34.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:34.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:34.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:34.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:34.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:34.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:34.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:34.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:34.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:34.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:34.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:34.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:34.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:34.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:34.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:34.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:34.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:34.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:34.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:33:34.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:33:34.844+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:34.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:33:34.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:33:34.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:33:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:33:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:33:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:33:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:34.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:34.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:34.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:33:34.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:33:34.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:33:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:33:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:33:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:33:34.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:34.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:34.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:34.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:33:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:33:34.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:33:34.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:33:34.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:33:34.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:33:34.849+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:33:44.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:44 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:33:44.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:44 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:33:44.809+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:33:44.810+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:44 ERROR Inbox: Ignoring error
[2025-05-22T15:33:44.811+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:44.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:44.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:33:44.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:33:44.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:33:44.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:33:44.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:33:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:33:44.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:33:44.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:33:44.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:33:44.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:33:44.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:33:44.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:33:44.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:33:44.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:33:44.819+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:33:44.820+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:33:44.820+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:33:44.820+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:33:44.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:33:44.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:33:44.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:33:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:33:44.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:44.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:44.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:44.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:44.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:44.826+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:44.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:44.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:44.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:44.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:44.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:33:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:33:44.830+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:44.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:33:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:33:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:33:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:33:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:33:44.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:33:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:44.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:33:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:33:44.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:33:44.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:33:44.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:33:44.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:33:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:44.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:44.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:44.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:33:44.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:33:44.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:33:44.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:33:44.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:33:44.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:33:44.838+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:33:44.838+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:44 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:33:44.838+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:44.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:33:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:33:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:33:44.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:33:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:33:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:33:44.840+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:33:44.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:33:44.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:33:44.841+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:33:44.841+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:33:44.841+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:33:44.841+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:33:44.841+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:33:44.842+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:44.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:33:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:33:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:33:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:33:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:33:44.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:33:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:33:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:33:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:33:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:33:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:33:44.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:33:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:33:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:33:44.845+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:33:44.845+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:33:44.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:33:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:33:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:33:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:33:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:44.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:44.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:44.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:44.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:44.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:44.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:33:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:33:44.850+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:44.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:33:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:33:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:33:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:33:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:33:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:33:44.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:33:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:33:44.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:33:44.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:33:44.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:33:44.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:33:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:44.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:44.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:44.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:33:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:33:44.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:33:44.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:33:44.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:33:44.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:33:44.856+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:33:54.805+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:54 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:33:54.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:54 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:33:54.809+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:33:54.810+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:54 ERROR Inbox: Ignoring error
[2025-05-22T15:33:54.811+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:54.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:54.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:54.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:33:54.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:33:54.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:33:54.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:33:54.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:33:54.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:33:54.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:33:54.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:33:54.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:33:54.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:33:54.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:33:54.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:33:54.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:33:54.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:33:54.820+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:33:54.821+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:33:54.821+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:33:54.821+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:33:54.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:33:54.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:33:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:33:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:33:54.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:54.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:54.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:54.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:54.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:54.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:54.828+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:54.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:54.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:54.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:54.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:33:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:33:54.832+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:54.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:33:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:33:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:33:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:33:54.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:33:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:33:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:54.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:33:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:33:54.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:33:54.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:33:54.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:33:54.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:33:54.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:54.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:54.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:54.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:54.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:54.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:54.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:54.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:54.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:54.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:54.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:33:54.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:33:54.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:33:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:33:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:33:54.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:33:54.840+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:33:54.840+0000] {spark_submit.py:492} INFO - 25/05/22 15:33:54 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:33:54.840+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:54.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:33:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:33:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:33:54.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:33:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:33:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:33:54.842+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:54.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:33:54.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:33:54.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:33:54.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:33:54.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:33:54.843+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:33:54.844+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:33:54.844+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:33:54.844+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:33:54.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:33:54.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:33:54.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:33:54.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:33:54.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:33:54.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:33:54.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:33:54.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:33:54.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:33:54.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:33:54.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:33:54.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:33:54.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:33:54.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:33:54.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:33:54.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:33:54.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:33:54.847+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:33:54.847+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:33:54.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:33:54.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:33:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:33:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:33:54.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:54.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:54.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:54.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:54.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:54.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:33:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:33:54.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:33:54.853+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:33:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:33:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:33:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:33:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:33:54.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:33:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:33:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:54.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:33:54.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:33:54.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:33:54.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:33:54.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:33:54.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:33:54.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:33:54.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:33:54.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:33:54.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:33:54.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:33:54.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:33:54.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:33:54.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:33:54.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:33:54.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:33:54.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:33:54.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:33:54.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:33:54.857+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:33:54.858+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:33:54.858+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:33:54.858+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:34:04.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:04 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:34:04.809+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:04 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:34:04.811+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:34:04.811+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:04 ERROR Inbox: Ignoring error
[2025-05-22T15:34:04.812+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:34:04.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:34:04.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:34:04.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:34:04.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:34:04.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:34:04.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:34:04.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:34:04.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:34:04.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:34:04.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:34:04.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:34:04.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:34:04.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:34:04.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:34:04.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:34:04.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:34:04.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:34:04.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:34:04.839+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:34:04.840+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:34:04.840+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:34:04.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:34:04.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:34:04.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:34:04.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:34:04.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:04.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:04.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:04.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:04.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:04.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:04.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:04.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:04.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:04.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:04.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:04.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:04.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:04.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:04.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:04.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:04.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:04.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:04.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:04.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:04.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:04.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:04.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:04.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:34:04.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:34:04.845+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:34:04.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:34:04.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:34:04.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:34:04.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:34:04.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:34:04.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:34:04.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:04.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:04.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:04.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:04.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:34:04.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:34:04.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:34:04.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:34:04.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:34:04.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:34:04.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:04.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:04.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:04.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:34:04.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:34:04.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:34:04.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:34:04.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:34:04.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:34:04.849+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:34:04.850+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:04 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:34:04.850+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:34:04.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:34:04.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:34:04.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:34:04.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:34:04.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:34:04.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:34:04.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:34:04.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:34:04.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:34:04.851+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:34:04.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:34:04.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:34:04.852+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:34:04.852+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:34:04.852+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:34:04.852+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:34:04.852+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:34:04.852+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:34:04.852+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:34:04.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:34:04.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:34:04.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:34:04.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:34:04.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:34:04.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:34:04.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:34:04.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:34:04.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:34:04.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:34:04.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:34:04.854+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:34:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:34:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:34:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:34:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:34:04.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:34:04.855+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:34:04.855+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:34:04.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:34:04.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:34:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:34:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:34:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:04.856+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:04.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:04.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:04.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:04.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:04.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:04.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:04.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:04.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:04.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:04.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:04.858+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:04.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:04.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:04.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:04.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:04.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:04.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:04.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:04.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:04.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:04.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:04.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:34:04.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:34:04.860+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:34:04.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:34:04.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:34:04.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:34:04.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:34:04.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:34:04.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:34:04.862+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:04.862+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:04.862+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:04.862+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:04.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:34:04.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:34:04.863+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:34:04.863+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:34:04.863+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:34:04.864+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:34:04.864+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:04.864+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:04.864+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:04.864+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:04.865+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:04.865+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:04.865+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:04.865+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:04.865+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:04.865+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:04.865+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:34:04.866+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:34:04.866+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:34:04.866+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:34:04.866+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:34:04.866+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:34:04.866+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:34:14.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:14 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:34:14.810+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:14 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:34:14.813+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:34:14.814+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:14 ERROR Inbox: Ignoring error
[2025-05-22T15:34:14.815+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:34:14.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:34:14.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:34:14.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:34:14.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:34:14.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:34:14.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:34:14.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:34:14.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:34:14.821+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:34:14.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:34:14.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:34:14.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:34:14.823+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:34:14.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:34:14.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:34:14.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:34:14.825+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:34:14.825+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:34:14.826+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:34:14.826+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:34:14.827+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:34:14.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:34:14.827+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:34:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:34:14.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:34:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:14.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:14.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:14.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:14.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:14.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:14.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:14.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:14.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:14.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:14.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:14.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:14.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:14.835+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:14.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:14.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:14.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:14.836+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:14.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:34:14.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:34:14.837+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:34:14.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:34:14.837+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:34:14.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:34:14.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:34:14.838+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:34:14.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:34:14.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:14.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:14.839+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:14.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:14.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:34:14.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:34:14.840+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:34:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:34:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:34:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:34:14.841+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:14.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:14.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:14.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:34:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:34:14.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:34:14.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:34:14.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:34:14.844+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:34:14.845+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:34:14.845+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:14 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:34:14.845+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:34:14.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:34:14.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:34:14.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:34:14.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:34:14.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:34:14.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:34:14.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:34:14.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:34:14.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:34:14.847+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:34:14.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:34:14.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:34:14.848+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:34:14.848+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:34:14.848+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:34:14.848+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:34:14.848+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:34:14.849+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:34:14.849+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:34:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:34:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:34:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:34:14.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:34:14.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:34:14.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:34:14.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:34:14.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:34:14.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:34:14.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:34:14.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:34:14.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:34:14.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:34:14.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:34:14.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:34:14.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:34:14.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:34:14.852+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:34:14.852+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:34:14.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:34:14.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:34:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:34:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:34:14.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:14.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:14.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:14.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:14.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:14.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:14.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:14.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:14.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:14.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:14.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:14.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:14.855+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:14.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:14.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:14.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:14.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:14.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:14.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:14.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:14.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:14.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:14.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:14.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:34:14.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:34:14.857+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:34:14.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:34:14.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:34:14.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:34:14.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:34:14.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:34:14.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:34:14.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:14.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:14.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:14.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:14.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:34:14.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:34:14.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:34:14.860+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:34:14.860+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:34:14.860+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:34:14.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:14.860+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:14.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:14.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:14.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:14.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:14.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:14.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:14.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:14.861+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:14.862+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:34:14.862+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:34:14.862+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:34:14.862+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:34:14.862+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:34:14.862+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:34:14.862+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:34:24.803+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:24 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:34:24.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:24 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:34:24.808+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:34:24.809+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:24 ERROR Inbox: Ignoring error
[2025-05-22T15:34:24.809+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:34:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:34:24.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:34:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:34:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:34:24.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:34:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:34:24.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:34:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:34:24.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:34:24.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:34:24.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:34:24.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:34:24.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:34:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:34:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:34:24.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:34:24.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:34:24.817+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:34:24.817+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:34:24.818+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:34:24.818+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:34:24.818+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:34:24.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:34:24.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:34:24.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:34:24.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:24.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:24.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:24.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:24.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:24.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:24.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:24.824+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:24.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:24.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:24.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:34:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:34:24.827+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:34:24.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:34:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:34:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:34:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:34:24.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:34:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:34:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:24.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:34:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:34:24.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:34:24.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:34:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:34:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:34:24.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:24.831+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:24.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:34:24.833+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:34:24.834+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:34:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:34:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:34:24.834+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:34:24.834+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:34:24.835+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:24 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:34:24.835+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:34:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:34:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:34:24.835+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:34:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:34:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:34:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:34:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:34:24.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:34:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:34:24.837+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:34:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:34:24.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:34:24.837+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:34:24.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:34:24.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:34:24.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:34:24.838+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:34:24.838+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:34:24.839+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:34:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:34:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:34:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:34:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:34:24.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:34:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:34:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:34:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:34:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:34:24.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:34:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:34:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:34:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:34:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:34:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:34:24.841+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:34:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:34:24.842+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:34:24.842+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:34:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:34:24.842+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:34:24.842+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:34:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:34:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:24.843+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:24.843+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:24.844+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:24.845+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:24.845+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:24.846+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:34:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:34:24.847+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:34:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:34:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:34:24.847+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:34:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:34:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:34:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:34:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:24.848+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:34:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:34:24.849+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:34:24.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:34:24.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:34:24.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:34:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:24.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:24.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:34:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:34:24.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:34:24.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:34:24.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:34:24.852+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:34:24.852+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:34:34.802+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:34 INFO Executor: Told to re-register on heartbeat
[2025-05-22T15:34:34.804+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:34 INFO BlockManager: BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None) re-registering with master
[2025-05-22T15:34:34.806+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e8ae60c88781, 37895, None)
[2025-05-22T15:34:34.807+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:34 ERROR Inbox: Ignoring error
[2025-05-22T15:34:34.808+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:34:34.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:34:34.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:34:34.809+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:34:34.810+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:34:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:34:34.811+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:34:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:34:34.812+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:34:34.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:34:34.813+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:34:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:34:34.814+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:34:34.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:34:34.815+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:34:34.816+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:34:34.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:34:34.817+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:34:34.817+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:34:34.818+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:34:34.818+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:34:34.818+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:34:34.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:34:34.819+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:34:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:34:34.819+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:34:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:34.820+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:34.820+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:34.821+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:34.822+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:34.822+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:34.823+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:34.824+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:34:34.825+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:34:34.826+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:34:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:34:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:34:34.826+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:34:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:34:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:34:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:34:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:34.827+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:34:34.828+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:34:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:34:34.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:34:34.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:34:34.829+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:34:34.829+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:34.830+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:34.830+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:34.831+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:34:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:34:34.832+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:34:34.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:34:34.832+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:34:34.833+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:34:34.833+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:34:34.833+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:34 WARN Executor: Issue communicating with driver in heartbeater
[2025-05-22T15:34:34.836+0000] {spark_submit.py:492} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:34:34.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:34:34.836+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:34:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:34:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-05-22T15:34:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-05-22T15:34:34.837+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-05-22T15:34:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2025-05-22T15:34:34.838+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2025-05-22T15:34:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2025-05-22T15:34:34.839+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:34:34.839+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2025-05-22T15:34:34.840+0000] {spark_submit.py:492} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-05-22T15:34:34.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-05-22T15:34:34.840+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-05-22T15:34:34.841+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-05-22T15:34:34.841+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-05-22T15:34:34.845+0000] {spark_submit.py:492} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-05-22T15:34:34.846+0000] {spark_submit.py:492} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-22T15:34:34.846+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-05-22T15:34:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2025-05-22T15:34:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2025-05-22T15:34:34.846+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-05-22T15:34:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-05-22T15:34:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-05-22T15:34:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-05-22T15:34:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2025-05-22T15:34:34.847+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2025-05-22T15:34:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2025-05-22T15:34:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2025-05-22T15:34:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2025-05-22T15:34:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2025-05-22T15:34:34.848+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-22T15:34:34.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-22T15:34:34.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-22T15:34:34.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-22T15:34:34.849+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-22T15:34:34.849+0000] {spark_submit.py:492} INFO - ... 3 more
[2025-05-22T15:34:34.850+0000] {spark_submit.py:492} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@e8ae60c88781:39397
[2025-05-22T15:34:34.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-05-22T15:34:34.850+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-05-22T15:34:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-05-22T15:34:34.850+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-05-22T15:34:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:34.851+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:34.851+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:34.852+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:34.853+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:34.853+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:34.854+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-05-22T15:34:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-05-22T15:34:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-05-22T15:34:34.855+0000] {spark_submit.py:492} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-22T15:34:34.855+0000] {spark_submit.py:492} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-05-22T15:34:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-05-22T15:34:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-05-22T15:34:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-05-22T15:34:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-05-22T15:34:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-05-22T15:34:34.856+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-05-22T15:34:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-05-22T15:34:34.857+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-05-22T15:34:34.858+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-05-22T15:34:34.858+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-05-22T15:34:34.858+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-05-22T15:34:34.858+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-05-22T15:34:34.858+0000] {spark_submit.py:492} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-05-22T15:34:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-05-22T15:34:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-05-22T15:34:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-05-22T15:34:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-05-22T15:34:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-05-22T15:34:34.859+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-05-22T15:34:34.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-05-22T15:34:34.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-05-22T15:34:34.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2025-05-22T15:34:34.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-05-22T15:34:34.860+0000] {spark_submit.py:492} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-05-22T15:34:34.860+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-05-22T15:34:34.861+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-05-22T15:34:34.861+0000] {spark_submit.py:492} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-05-22T15:34:34.861+0000] {spark_submit.py:492} INFO - ... 8 more
[2025-05-22T15:34:34.861+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:34 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times
[2025-05-22T15:34:44.827+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO SparkContext: Invoking stop() from shutdown hook
[2025-05-22T15:34:44.829+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-05-22T15:34:44.851+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO SparkUI: Stopped Spark web UI at http://e8ae60c88781:4040
[2025-05-22T15:34:44.861+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-05-22T15:34:44.871+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO MemoryStore: MemoryStore cleared
[2025-05-22T15:34:44.871+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO BlockManager: BlockManager stopped
[2025-05-22T15:34:44.874+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-05-22T15:34:44.876+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-05-22T15:34:44.893+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO SparkContext: Successfully stopped SparkContext
[2025-05-22T15:34:44.893+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO ShutdownHookManager: Shutdown hook called
[2025-05-22T15:34:44.893+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-01eac6bd-9150-4bd6-a9ed-ad9f95de7cda
[2025-05-22T15:34:44.895+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-a2a94b99-b9fd-40b5-afd7-06f163a1f37f
[2025-05-22T15:34:44.896+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-01eac6bd-9150-4bd6-a9ed-ad9f95de7cda/pyspark-c4c08a89-07b1-4ac2-a1cc-6095b67faf3b
[2025-05-22T15:34:44.899+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
[2025-05-22T15:34:44.899+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
[2025-05-22T15:34:44.899+0000] {spark_submit.py:492} INFO - 25/05/22 15:34:44 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
[2025-05-22T15:34:45.341+0000] {taskinstance.py:3310} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 762, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 157, in execute
    self._hook.submit(self._application)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 423, in submit
    raise AirflowException(
airflow.exceptions.AirflowException: Cannot execute: spark-submit --master local --conf spark.hadoop.fs.s3a.endpoint=http://3.38.135.214:9000 --conf spark.hadoop.fs.s3a.access.key=minioadmin --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.hadoop.fs.s3a.aws.credentials.provider= --jars /opt/spark/jars/hadoop-aws-3.3.1.jar,/opt/spark/jars/aws-java-sdk-bundle-1.11.901.jar,/opt/spark/jars/postgresql-42.7.4.jar --name arrow-spark /opt/spark/testlog_ml_spark.py. Error code is: 56.
[2025-05-22T15:34:45.349+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=kafka_to_minio_to_spark, task_id=spark_etl, run_id=scheduled__2025-05-21T16:00:00+00:00, execution_date=20250521T160000, start_date=20250522T132808, end_date=20250522T153445
[2025-05-22T15:34:45.360+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-05-22T15:34:45.361+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 337 for task spark_etl (Cannot execute: spark-submit --master local --conf spark.hadoop.fs.s3a.endpoint=http://3.38.135.214:9000 --conf spark.hadoop.fs.s3a.access.key=minioadmin --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.hadoop.fs.s3a.aws.credentials.provider= --jars /opt/spark/jars/hadoop-aws-3.3.1.jar,/opt/spark/jars/aws-java-sdk-bundle-1.11.901.jar,/opt/spark/jars/postgresql-42.7.4.jar --name arrow-spark /opt/spark/testlog_ml_spark.py. Error code is: 56.; 78)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 115, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 3004, in _run_raw_task
    return _run_raw_task(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 3158, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 3182, in _execute_task
    return _execute_task(self, context, task_orig)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 762, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 157, in execute
    self._hook.submit(self._application)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 423, in submit
    raise AirflowException(
airflow.exceptions.AirflowException: Cannot execute: spark-submit --master local --conf spark.hadoop.fs.s3a.endpoint=http://3.38.135.214:9000 --conf spark.hadoop.fs.s3a.access.key=minioadmin --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.hadoop.fs.s3a.aws.credentials.provider= --jars /opt/spark/jars/hadoop-aws-3.3.1.jar,/opt/spark/jars/aws-java-sdk-bundle-1.11.901.jar,/opt/spark/jars/postgresql-42.7.4.jar --name arrow-spark /opt/spark/testlog_ml_spark.py. Error code is: 56.
[2025-05-22T15:34:45.406+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-05-22T15:34:45.415+0000] {taskinstance.py:3900} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-05-22T15:34:45.416+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
